{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/evn python\n",
    "\n",
    "\"\"\"\n",
    "CMSC733 Spring 2019: Classical and Deep Learning Approaches for\n",
    "Geometric Computer Vision\n",
    "Project1: MyAutoPano: Phase 1 Starter Code\n",
    "\n",
    "Author(s): \n",
    "Chahat Deep Singh (chahat@terpmail.umd.edu) \n",
    "PhD Student in Computer Science,\n",
    "University of Maryland, College Park\n",
    "\n",
    "Nitin J. Sanket (nitinsan@terpmail.umd.edu)\n",
    "PhD Candidate in Computer Science,\n",
    "University of Maryland, College Park\n",
    "\"\"\"\n",
    "\n",
    "#Code starts here:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.feature import peak_local_max\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImageSet(folder_name):\n",
    "    print(\"Reading images from \", folder_name)\n",
    "    images = []\n",
    "    files = os.listdir(folder_name)\t\n",
    "    files = sorted(files)\n",
    "    print(\"Found \", files)\n",
    "    for file in files:\n",
    "        image_path = folder_name + \"/\" + file\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            images.append(image)\t\t\t\n",
    "        else:\n",
    "            print(\"Error in loading image \", image)\n",
    "\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImages(image_array, name):\n",
    "\n",
    "    image_array = makeImageSizeSame(image_array)\n",
    "    concat = image_array[0].copy()\n",
    "\n",
    "    for l in range(1,len(image_array)):\n",
    "        image = image_array[l]\n",
    "        concat = np.concatenate((concat,image), axis = 1)\n",
    "        \n",
    "    cv2.imshow(name, concat)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCorners(images, choice):\n",
    "    print(\"detecting corners ...\")\n",
    "    detected_corners = []\n",
    "    cmaps = []\n",
    "    corner_images = []\n",
    "    for i in images:\n",
    "        image = i.copy()\n",
    "        gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        gray_image = np.float32(gray_image)\n",
    "\n",
    "\n",
    "        if(choice == 1):\n",
    "            print(\"using Harris corner detection method.\")\n",
    "            corner_strength = cv2.cornerHarris(gray_image,2,3,0.04)\n",
    "            corner_strength[corner_strength<0.01*corner_strength.max()] = 0\n",
    "            detected_corner = np.where(corner_strength>0.001*corner_strength.max())\n",
    "            detected_corners.append(detected_corner)\n",
    "            cmaps.append(corner_strength)\n",
    "            image[corner_strength > 0.001*corner_strength.max()]=[0,0,255]\n",
    "            corner_images.append(image)\n",
    "        else:\n",
    "            print(\"using Shi-Tomashi corner detection method.\")\n",
    "            dst = cv2.goodFeaturesToTrack(gray_image, 1000 ,0.01, 10)\n",
    "            dst = np.int0(dst)\n",
    "            detected_corners.append(dst)\n",
    "            for c in dst:\n",
    "                x,y = c.ravel()\n",
    "                cv2.circle(image,(x,y),3,(0, 0, 255),-1) \n",
    "                          \n",
    "            corner_images.append(image)\n",
    "            cmap = np.zeros(gray_image.shape) #not sure what to do\n",
    "            cmaps.append(cmap)\n",
    "    #filter detected corners\n",
    "    #remove the corner one\n",
    "    return detected_corners, cmaps, corner_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureDescriptor(gray_image,x,y, patch_size=40):\n",
    "    patch = gray_image[x-patch_size//2:x+patch_size//2, y-patch_size//2:y+patch_size//2] \n",
    "    # gaussian blur\n",
    "    patch = cv2.GaussianBlur(patch,(3,3),0)\n",
    "    # subsample to 20% size or 1/5th\n",
    "    patch = cv2.resize(patch, None, fx=0.2, fy=0.2, interpolation = cv2.INTER_CUBIC)\n",
    "    feature = patch.reshape(-1)\n",
    "    feature = (feature-feature.mean())/ np.std(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPairs(image_1, image_2, all_corners_1, all_corners_2, patch_size = 40, alpha = 0.8):\n",
    "\n",
    "    gray_image1 = cv2.cvtColor(image_1,cv2.COLOR_BGR2GRAY)\n",
    "    gray_image2 = cv2.cvtColor(image_2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    width1, height1 = image_1.shape[:2]\n",
    "    width2, height2 = image_2.shape[:2]\n",
    "\n",
    "    print(\"width = \", width1, \", height = \", height1)\n",
    "    print(\"width = \", width2, \", height = \", height2)\n",
    "\n",
    "    features_1,features_2 = [], []\n",
    "    corners_1, corners_2 = [],[]\n",
    "\n",
    "    print(\"all corner 1 len = \", len(all_corners_1))\n",
    "    print(\"all corner 2 len = \", len(all_corners_2))\n",
    "    \n",
    "    for corner in all_corners_1:\n",
    "        x,y = corner.ravel()\n",
    "        \n",
    "        if (x - (patch_size / 2) > 0) & (x + (patch_size / 2) < height1) & (y - (patch_size / 2) > 0) & (y + (patch_size / 2) < width1):\n",
    "            features_1.append(getFeatureDescriptor(gray_image1, y,x)) \n",
    "            corners_1.append([x,y])\n",
    "        else:\n",
    "            #print(\"ignored x, y\", x, y)\n",
    "            pass\n",
    "\n",
    "    for corner in all_corners_2:\n",
    "        x,y = corner.ravel()\n",
    "        if (x - (patch_size / 2) > 0) & (x + (patch_size / 2) < height2) & (y - (patch_size / 2) > 0) & (y + (patch_size / 2) < width2):\n",
    "            features_2.append(getFeatureDescriptor(gray_image2, y,x)) \n",
    "            corners_2.append([x,y]) \n",
    "\n",
    "    matched_pairs, match_level = [], []\n",
    "    for i, feat_1 in enumerate(features_1):\n",
    "        ssd = []  \n",
    "        for j, feat_2 in enumerate(features_2):\n",
    "            ssd.append(np.sum((feat_1 - feat_2)**2))\n",
    "        top_matche = np.argmin(ssd)\n",
    "        #if ssd[top_matches[0]] / ssd[top_matches[1]] < alpha:   \n",
    "            #matched_pairs.append([corners_1[i] , corners_2[top_matches[0]]])\n",
    "        matched_pairs.append([corners_1[i] , corners_2[top_matche]]) \n",
    "    print(\"matched pairs num = \", len(matched_pairs))\n",
    "    matched_pairs = np.array(matched_pairs)\n",
    "    return matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImageSizeSame(images):\n",
    "    sizes = []\n",
    "    for image in images:\n",
    "        x, y, ch = image.shape\n",
    "        sizes.append([x, y, ch])\n",
    "\n",
    "    sizes = np.array(sizes)\n",
    "    x_target, y_target, _ = np.max(sizes, axis = 0)\n",
    "    \n",
    "    images_resized = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image_resized = np.zeros((x_target, y_target, sizes[i, 2]), np.uint8)\n",
    "        image_resized[0:sizes[i, 0], 0:sizes[i, 1], 0:sizes[i, 2]] = image\n",
    "        images_resized.append(image_resized)\n",
    "\n",
    "    return images_resized\n",
    "\n",
    "\n",
    "def showMatches(image_1, image_2, matched_pairs, partition_width = 20):\n",
    "\n",
    "    image_1, image_2 = makeImageSizeSame([image_1, image_2])\n",
    "\n",
    "    concat = np.concatenate((image_1, image_2), axis = 1)\n",
    "    corners_1 = matched_pairs[:,0].copy()\n",
    "    corners_2  = matched_pairs[:,1].copy()\n",
    "    corners_2[:,0] += image_1.shape[1]\n",
    "\n",
    "    for (x1,y1) , (x2,y2) in zip(corners_1, corners_2):\n",
    "        cv2.line(concat, (x1,y1), (x2,y2), (0, 0, 255), 1)\n",
    "    \n",
    "      \n",
    "    cv2.imshow('Feature_matches', concat)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def testShowMatches(image_1, image_2, partition_width = 20):\n",
    "    matched_pairs= []\n",
    "    I = np.linspace(10, 100, 10)\n",
    "    for i in I:\n",
    "        x1 = i\n",
    "        y1 = i\n",
    "        corner1 = np.int0(np.array([x1, y1]))\n",
    "\n",
    "        x2 = i\n",
    "        y2 = i\n",
    "        corner2 = np.int0(np.array([x2, y2]))\n",
    "        matched_pairs.append([corner1 , corner2])\n",
    "\n",
    "    matched_pairs = np.array(matched_pairs)\n",
    "    showMatches(image_1, image_2, matched_pairs, partition_width = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutliers(matched_pairs, outliers, accuracy, thresh):\n",
    "\n",
    "    set1 = matched_pairs[:, 0]\n",
    "    set2 = matched_pairs[:, 1]\n",
    "\n",
    "    N_best = 0\n",
    "    H_best = np.zeros([3, 3])\n",
    "    \n",
    "    e = outliers / set1.shape[0]\n",
    "    s = 4\n",
    "    p = accuracy\n",
    "    iterations = np.log(1 - p) / np.log(1 - np.power((1 - e), s))\n",
    "    iterations = np.int(iterations)\n",
    "    iterations = 4000\n",
    "\n",
    "    filtered_pair_indices = []\n",
    "\n",
    "    print(\"iterations = \", iterations)\n",
    "    for i in range(iterations):\n",
    "        #randomly select four points\n",
    "        n_rows = set1.shape[0]\n",
    "        random_indices = np.random.choice(n_rows, size=4)\n",
    "\n",
    "        set1_random = set1[random_indices]\n",
    "        set2_random = set2[random_indices]\n",
    "              \n",
    "        #compute homography\n",
    "        H = cv2.getPerspectiveTransform(np.float32(set1_random), np.float32(set2_random))\n",
    "\n",
    "        set1_dash = np.vstack((set1[:,0], set1[:,1], np.ones([1, n_rows])))\n",
    "        set1_transformed_dash = np.dot(H, set1_dash)\n",
    "        \n",
    "        t1 = set1_transformed_dash[0,:]/set1_transformed_dash[2,:]\n",
    "        t2 = set1_transformed_dash[1,:]/set1_transformed_dash[2,:]\n",
    "\n",
    "        set1_transformed = np.array([t1, t2]).T\n",
    "        #print(set1_transformed.shape)\n",
    "\n",
    "        E = calculateError(set2, set1_transformed)\n",
    "        \n",
    "     \n",
    "        E[E <= thresh] = 1\n",
    "        E[E > thresh] = 0\n",
    "    \n",
    "    \n",
    "        N = np.sum(E)\n",
    "\n",
    "\n",
    "        if N > N_best:\n",
    "            N_best = N\n",
    "            H_best = H\n",
    "            filtered_pair_indices = np.where(E == 1)\n",
    "    \n",
    "    filtered_set1 =  set1[filtered_pair_indices]\n",
    "    filtered_set2 =  set2[filtered_pair_indices]\n",
    "\n",
    "    print(\"Number of pairs after filtering = \", filtered_set1.shape[0])\n",
    "\n",
    "    filter_matched_pairs = np.zeros([filtered_set1.shape[0], filtered_set1.shape[1], 2])\n",
    "\n",
    "    filter_matched_pairs[:, 0, :] = filtered_set1\n",
    "    filter_matched_pairs[:, 1, :] = filtered_set2\n",
    "\n",
    "    filter_matched_pairs = filter_matched_pairs.astype(int)\n",
    "\n",
    "    H_inbuit, _ = cv2.findHomography(set1, set2)\n",
    "    print(\"inbuilt = \", H_inbuit)\n",
    "    print(\"Computed = \", H_best)\n",
    "\n",
    "    return H_best, filter_matched_pairs\n",
    "\n",
    "def calculateError(set1, set2):\n",
    "   \n",
    "    E = np.zeros(set1.shape[0])\n",
    "    tmp = set2 - set1\n",
    "    num = set1.shape[0]\n",
    "\n",
    "    for n in range(num):\n",
    "        E[n] = np.linalg.norm(tmp[n])\n",
    "    return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaptiveNonMaximalSuppression(images, C_maps, N_best):\n",
    "\n",
    "    anms_img = []\n",
    "    anms_corners = []\n",
    "    for i,image in enumerate(images):\n",
    "\n",
    "        cmap = C_maps[i]\n",
    "        local_maximas = peak_local_max(cmap, min_distance=10)\n",
    "        n_strong = local_maximas.shape[0]\n",
    "        \n",
    "        r = [np.Infinity for i in range(n_strong)]\n",
    "        x=np.zeros((n_strong,1))\n",
    "        y=np.zeros((n_strong,1))\n",
    "        eu_dist = 0\n",
    "\n",
    "        for i in range(n_strong):\n",
    "            for j in range(n_strong):\n",
    "                x_j = local_maximas[j][0]\n",
    "                y_j = local_maximas[j][1]\n",
    "\n",
    "                x_i = local_maximas[i][0]\n",
    "                y_i = local_maximas[i][1]\n",
    "\n",
    "                if(cmap[x_j, y_j] > cmap[x_i, y_i]):\n",
    "                    eu_dist = np.square(x_j - x_i) + np.square(y_j - y_i)\n",
    "                if r[i] > eu_dist:\n",
    "                    r[i] = eu_dist\n",
    "                    x[i] = x_j\n",
    "                    y[i] = y_j\n",
    "\n",
    "        index = np.argsort(r)\n",
    "        index = np.flip(index)\n",
    "        index = index[0:N_best]\n",
    "        x_best=np.zeros((N_best,1))\n",
    "        y_best=np.zeros((N_best,1))\n",
    "\n",
    "        for i in range(N_best):\n",
    "            x_best[i] = np.int0(x[index[i]])\n",
    "            y_best[i] = np.int0(y[index[i]]) \n",
    "            cv2.circle(image, (y_best[i], x_best[i]), 3, (0, 255, 0), -1)\n",
    "\n",
    "        anms_corner = np.int0(np.concatenate((x_best, y_best), axis = 1))\n",
    "        anms_corners.append(anms_corner)\n",
    "        anms_img.append(image)\n",
    "    return anms_corners, anms_img\n",
    "\n",
    "def trim(image):\n",
    "\n",
    "    if not np.sum(image[0]):\n",
    "        return trim(image[1:])\n",
    "\n",
    "    if not np.sum(image[-1]):\n",
    "        return trim(image[:-2])\n",
    "    #crop top\n",
    "    if not np.sum(image[:,0]):\n",
    "        return trim(image[:,1:])\n",
    "    #crop top\n",
    "    if not np.sum(image[:,-1]):\n",
    "        return trim(image[:,:-2])\n",
    "    return image\n",
    "\n",
    "def stitchImagePairs(image0, image1, H):\n",
    "\n",
    "    #stitch image 0 on image 1\n",
    "    print(\"shapes\")\n",
    "    print(image0.shape)\n",
    "    print(image1.shape)\n",
    "    \n",
    "\n",
    "    h0 ,w0 ,_ = image0.shape\n",
    "    h1 ,w1 ,_ = image1.shape\n",
    "\n",
    "    points_on_image0 = np.float32([[0, 0], [0, h0], [w0, h0], [w0, 0]]).reshape(-1,1,2)\n",
    "    points_on_image0_transformed = cv2.perspectiveTransform(points_on_image0, H)\n",
    "    print(\"transformed points = \", points_on_image0_transformed)\n",
    "    points_on_image1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1,1,2)\n",
    "\n",
    "    points_on_merged_images = np.concatenate((points_on_image0_transformed, points_on_image1), axis = 0)\n",
    "    points_on_merged_images_ = []\n",
    "\n",
    "    for p in range(len(points_on_merged_images)):\n",
    "        points_on_merged_images_.append(points_on_merged_images[p].ravel())\n",
    "\n",
    "    points_on_merged_images_ = np.array(points_on_merged_images_)\n",
    "\n",
    "    x_min, y_min = np.int0(np.min(points_on_merged_images_, axis = 0))\n",
    "    x_max, y_max = np.int0(np.max(points_on_merged_images_, axis = 0))\n",
    "\n",
    "    print(\"min, max\")\n",
    "    print(x_min, y_min)\n",
    "    print(x_max, y_max)\n",
    "\n",
    "    # overlap_area = cv2.polylines(image1,[np.int32(points_on_image0_transformed)],True,255,3, cv2.LINE_AA) \n",
    "    # cv2.imshow(\"original_image_overlapping.jpg\", overlap_area)\n",
    "    # cv2.waitKey() \n",
    "    # cv2.destroyAllWindows()\n",
    "    H_translate = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]]) # translate\n",
    "\n",
    "    image0_transformed = cv2.warpPerspective(image0, np.dot(H_translate, H), (x_max-x_min, y_max-y_min))\n",
    "    image0_transformed[-y_min:-y_min+h1, -x_min: -x_min+w1] = image1\n",
    "    return(image0_transformed)\n",
    "\n",
    "def stitchImageArray(image_array, H_array):\n",
    "    \n",
    "    N = len(image_array)\n",
    "\n",
    "    target_image = image_array[N-1]\n",
    "\n",
    "    ht, wt, _ = target_image.shape\n",
    "    points_on_target_image = np.float32([[0, 0], [0, ht], [wt, ht], [wt, 0]]).reshape(-1,1,2)\n",
    "\n",
    "    points = points_on_target_image\n",
    "    \n",
    "    images_transformed = []\n",
    "    H_translate_array = []\n",
    "\n",
    "    for n in range(N-1):\n",
    "        image = image_array[n]\n",
    "        h, w, _ = image.shape\n",
    "        points_on_image = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1,1,2)\n",
    "\n",
    "        points_on_image_transformed = points_on_image \n",
    "        for m in range(n, N-1):\n",
    "            H = H_array[m]\n",
    "            points_on_image_transformed = cv2.perspectiveTransform(points_on_image_transformed, H)\n",
    "        \n",
    "        points = np.concatenate((points, points_on_image_transformed), axis = 0)\n",
    "\n",
    "    points_ = []\n",
    "    for p in range(len(points)):\n",
    "        points_.append(points[p].ravel())\n",
    "\n",
    "    points_ = np.array(points_)\n",
    "\n",
    "    x_min, y_min = np.int0(np.min(points_, axis = 0))\n",
    "    x_max, y_max = np.int0(np.max(points_, axis = 0))\n",
    "\n",
    "    H_translate = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]]) # translate\n",
    "\n",
    "    for n in range(N-1):\n",
    "        image = image_array[n]\n",
    "        image_transformed = image\n",
    "        for m in range(n, N-1):\n",
    "            H = H_array[m]\n",
    "            image_transformed = cv2.warpPerspective(image_transformed, np.dot(H_translate,H), (x_max-x_min, y_max-y_min))\n",
    "\n",
    "        #image_transformed = cv2.warpAffine(image_transformed, H_translate, (x_max-x_min, y_max-y_min))\n",
    "        images_transformed.append(image_transformed)\n",
    "\n",
    "    final_output = np.zeros((y_max-y_min, x_max-x_min, 3), np.uint8)\n",
    "    for i in range(len(images_transformed)):\n",
    "        final_output = final_output + images_transformed[i]\n",
    "\n",
    "    return images_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Add any Command Line arguments here\n",
    "    # Parser = argparse.ArgumentParser()\n",
    "    # Parser.add_argument('--NumFeatures', default=100, help='Number of best features to extract from each image, Default:100')\n",
    "    \n",
    "    # Args = Parser.parse_args()\n",
    "    # NumFeatures = Args.NumFeatures\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Read a set of images for Panorama stitching\n",
    "    \"\"\"\n",
    "    print(\"main\")\n",
    "    folder_name = \"/home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Train/Set1\"\n",
    "    use_harris = False\n",
    "    images = readImageSet(folder_name)\n",
    "    displayImages(images, \"image_set\")\n",
    "    N_images = len(images)\n",
    "\n",
    "    choice = 2\n",
    "    if use_harris:\n",
    "        choice = 1\n",
    "\n",
    "    image0 = images[0]\n",
    "\n",
    "    for i in range(1, N_images):\n",
    "\n",
    "        print(\"processing image \", i)\n",
    "        image1 = images[i] \n",
    "\n",
    "        image_pair = [image0, image1]\n",
    "        \n",
    "        detected_corners, cmaps, corner_images = detectCorners(image_pair, choice)\n",
    "        displayImages(corner_images, \"corners\")\n",
    "        \"\"\"\n",
    "        Perform ANMS: Adaptive Non-Maximal Suppression\n",
    "        Save ANMS output as anms.png\n",
    "        \"\"\"\n",
    "        if (choice == 1):\n",
    "            print(\"Applying ALMS.\")\n",
    "            detected_corners, anms_image = AdaptiveNonMaximalSuppression(image_pair, cmaps, 500)\n",
    "            displayImages(anms_image, \"anms_output\")\n",
    "        else:\n",
    "            print(\"goodFeaturesToTrack is already using ALMS.\") #review\n",
    "\n",
    "        detected_corners0 = detected_corners[0]\n",
    "        detected_corners1 = detected_corners[1]\n",
    "            \n",
    "        matched_pairs = getPairs(image0, image1, detected_corners0, detected_corners1, patch_size = 40, alpha = 0.9 )\n",
    "        showMatches(image0, image1, matched_pairs, partition_width = 20)\n",
    "        \"\"\"\n",
    "        Refine: RANSAC, Estimate Homography\n",
    "        \"\"\"\n",
    "        H,filtered_matched_pairs = filterOutliers(matched_pairs, 20, 0.9, 5)\n",
    "        showMatches(image0, image1, filtered_matched_pairs, partition_width = 20)\n",
    "        \"\"\"\n",
    "        Image Warping + Blending\n",
    "        Save Panorama output as mypano.png\n",
    "        \"\"\"\n",
    "        stitched_image = stitchImagePairs(image0, image1, H)\n",
    "        cv2.imshow(\"pano.jpg\", stitched_image)\n",
    "        cv2.waitKey() \n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.imwrite(\"pano.png\", stitched_image)\n",
    "        image0 = stitched_image\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from  /home/gokul/CMSC733/hgokul_p1/Phase1/Data/Train/Set3\n",
      "Found  ['.ipynb_checkpoints', '1.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg']\n",
      "Error in loading image  None\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  807 , height =  605\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  489\n",
      "all corner 2 len =  561\n",
      "matched pairs num =  442\n",
      "iterations =  4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/.local/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/gokul/.local/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/gokul/.local/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/gokul/.local/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs after filtering =  54\n",
      "inbuilt =  [[ 8.98932359e-01 -8.09269316e-01  2.35080040e+02]\n",
      " [ 1.94672202e+00 -1.72142241e+00  4.96172856e+02]\n",
      " [ 3.89482378e-03 -3.46407303e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.53812163e+00  2.54333763e-02 -4.63165300e+02]\n",
      " [ 3.07842725e-01  1.24695646e+00 -1.01647542e+02]\n",
      " [ 1.00944077e-03 -2.45239072e-04  1.00000000e+00]]\n",
      "shapes\n",
      "(807, 605, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[-463.1653   -101.647545]]\n",
      "\n",
      " [[-551.85754  1127.8584  ]]\n",
      "\n",
      " [[ 345.35797   772.1463  ]]\n",
      "\n",
      " [[ 290.1812     52.521694]]]\n",
      "min, max\n",
      "-551 -101\n",
      "605 1127\n",
      "processing image  2\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  1228 , height =  1156\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  798\n",
      "all corner 2 len =  429\n",
      "matched pairs num =  783\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  36\n",
      "inbuilt =  [[-2.15014196e+00  8.29549937e-01  9.21498772e+02]\n",
      " [-1.87829976e+00  7.53299632e-01  7.84785329e+02]\n",
      " [-2.44032619e-03  1.00692005e-03  1.00000000e+00]]\n",
      "Computed =  [[ 3.27531101e+00 -5.82400905e-02 -2.67787083e+03]\n",
      " [ 7.37735065e-01  2.90028008e+00 -9.31976318e+02]\n",
      " [ 2.02633777e-03 -5.30959261e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(1228, 1156, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[-2677.8708    -931.9763  ]]\n",
      "\n",
      " [[-2941.1584    2812.979   ]]\n",
      "\n",
      " [[  316.38464   1062.5967  ]]\n",
      "\n",
      " [[  331.61002    -23.681631]]]\n",
      "min, max\n",
      "-2941 -931\n",
      "605 2812\n",
      "processing image  3\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  3743 , height =  3546\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  1000\n",
      "all corner 2 len =  422\n",
      "matched pairs num =  985\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  110\n",
      "inbuilt =  [[-1.56274096e-01  2.99480612e-02  3.34253671e+02]\n",
      " [-1.60728208e+00  8.31917981e-02  3.86267110e+03]\n",
      " [-4.79251066e-04  1.05143814e-04  1.00000000e+00]]\n",
      "Computed =  [[-1.45085480e+00 -1.02583051e-01  4.68763006e+03]\n",
      " [-1.95180653e-01 -1.33380025e+00  1.89324184e+03]\n",
      " [-6.65121288e-04 -7.53858230e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(3743, 3546, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[ 4687.63     1893.2418 ]]\n",
      "\n",
      " [[ 5995.37    -4317.413  ]]\n",
      "\n",
      " [[  512.6318   2310.7869 ]]\n",
      "\n",
      " [[  336.46988  -884.14685]]]\n",
      "min, max\n",
      "0 -4317\n",
      "5995 2310\n",
      "processing image  4\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  6627 , height =  5995\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  448\n",
      "all corner 2 len =  435\n",
      "matched pairs num =  440\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  153\n",
      "inbuilt =  [[-3.09245264e-03 -4.84314507e-02  2.32288301e+02]\n",
      " [-3.16579281e-03 -4.96464945e-02  2.38074480e+02]\n",
      " [-1.28207277e-05 -2.08534666e-04  1.00000000e+00]]\n",
      "Computed =  [[ 1.40963775e+00  9.64529639e-03 -3.29900709e+02]\n",
      " [ 1.96585340e-01  1.34283434e+00 -5.87235319e+03]\n",
      " [ 5.25316151e-04  2.24140346e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(6627, 5995, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[ -329.9007  -5872.353  ]]\n",
      "\n",
      " [[ -231.58257  2635.1853 ]]\n",
      "\n",
      " [[ 1904.4119    978.43805]]\n",
      "\n",
      " [[ 1957.1821  -1131.2408 ]]]\n",
      "min, max\n",
      "-329 -5872\n",
      "1957 2635\n",
      "processing image  5\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  8507 , height =  2286\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  594\n",
      "all corner 2 len =  360\n",
      "matched pairs num =  591\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  63\n",
      "inbuilt =  [[-5.40168521e-02 -6.82250220e-02  4.55516761e+02]\n",
      " [-7.57240051e-02 -9.45086853e-02  6.31241616e+02]\n",
      " [-1.21408176e-04 -1.49651518e-04  1.00000000e+00]]\n",
      "Computed =  [[-2.90753558e-01 -1.63973829e-02  2.56952628e+02]\n",
      " [-1.47621807e-02 -3.55058180e-01  2.13935875e+03]\n",
      " [-5.50587681e-05 -1.92967673e-04  1.00000000e+00]]\n",
      "shapes\n",
      "(8507, 2286, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[ 256.95264 2139.3586 ]]\n",
      "\n",
      " [[-183.08057 1373.37   ]]\n",
      "\n",
      " [[ 713.0229  1192.1025 ]]\n",
      "\n",
      " [[-466.41504 2408.7937 ]]]\n",
      "min, max\n",
      "-466 0\n",
      "713 2408\n",
      "processing image  6\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  2408 , height =  1179\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  595\n",
      "all corner 2 len =  371\n",
      "matched pairs num =  590\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  122\n",
      "inbuilt =  [[ 2.46481247e-01 -8.75770191e-01  2.92556522e+02]\n",
      " [ 4.79506138e-01 -1.70319903e+00  5.68965735e+02]\n",
      " [ 8.43086609e-04 -2.99364338e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.24507982e+00 -3.04910528e-02 -7.25724009e+02]\n",
      " [ 8.83790725e-02  1.19109401e+00 -5.37476931e+01]\n",
      " [ 3.34974979e-04 -8.82547022e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(2408, 1179, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[ -725.724      -53.747692]]\n",
      "\n",
      " [[-1014.81146   3573.9285  ]]\n",
      "\n",
      " [[  565.6228    2468.3362  ]]\n",
      "\n",
      " [[  532.08563     36.16743 ]]]\n",
      "min, max\n",
      "-1014 -53\n",
      "605 3573\n",
      "processing image  7\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  3626 , height =  1619\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  720\n",
      "all corner 2 len =  338\n",
      "matched pairs num =  706\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  149\n",
      "inbuilt =  [[-1.99221141e-02 -4.31277841e-01  2.52749960e+02]\n",
      " [-1.47551211e-01 -1.02615268e+00  2.52283616e+02]\n",
      " [ 4.73704489e-04 -2.60620860e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.93935523e+00 -8.22749328e-02 -2.20369518e+03]\n",
      " [ 2.35494828e-01  1.79622128e+00 -4.06541186e+02]\n",
      " [ 6.27613541e-04 -7.21292553e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(3626, 1619, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[-2203.695     -406.5412  ]]\n",
      "\n",
      " [[-3388.1677    8269.321   ]]\n",
      "\n",
      " [[  363.5042    3697.6807  ]]\n",
      "\n",
      " [[  464.3212     -12.536571]]]\n",
      "min, max\n",
      "-3388 -406\n",
      "605 8269\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"/home/gokul/CMSC733/hgokul_p1/Phase1/Data/Train/Set3\"\n",
    "use_harris = False\n",
    "\n",
    "images = readImageSet(folder_name)\n",
    "displayImages(images, \"image_set\")\n",
    "N_images = len(images)\n",
    "\n",
    "choice = 2\n",
    "if use_harris:\n",
    "    choice = 1\n",
    "\n",
    "image0 = images[0]\n",
    "\n",
    "for i in range(1, N_images):\n",
    "\n",
    "    print(\"processing image \", i)\n",
    "    image1 = images[i] \n",
    "\n",
    "    image_pair = [image0, image1]\n",
    "        \n",
    "    detected_corners, cmaps, corner_images = detectCorners(image_pair, choice)\n",
    "#     displayImages(corner_images, \"corners\")\n",
    "    \"\"\"\n",
    "    Perform ANMS: Adaptive Non-Maximal Suppression\n",
    "    Save ANMS output as anms.png\n",
    "    \"\"\"\n",
    "    if (choice == 1):\n",
    "        print(\"Applying ALMS.\")\n",
    "        detected_corners, anms_image = AdaptiveNonMaximalSuppression(image_pair, cmaps, 500)\n",
    "#         displayImages(anms_image, \"anms_output\")\n",
    "    else:\n",
    "        print(\"goodFeaturesToTrack is already using ALMS.\") #review\n",
    "\n",
    "    detected_corners0 = detected_corners[0]\n",
    "    detected_corners1 = detected_corners[1]\n",
    "        \n",
    "    matched_pairs = getPairs(image0, image1, detected_corners0, detected_corners1, patch_size = 40, alpha = 0.9 )\n",
    "#     showMatches(image0, image1, matched_pairs, partition_width = 20)\n",
    "    \"\"\"\n",
    "    Refine: RANSAC, Estimate Homography\n",
    "    \"\"\"\n",
    "    H,filtered_matched_pairs = filterOutliers(matched_pairs, 20, 0.9, 5)\n",
    "#     showMatches(image0, image1, filtered_matched_pairs, partition_width = 20)\n",
    "    \"\"\"\n",
    "    Image Warping + Blending\n",
    "    Save Panorama output as mypano.png\n",
    "    \"\"\"\n",
    "    stitched_image = stitchImagePairs(image0, image1, H)\n",
    "    cv2.imshow(\"pano.jpg\", stitched_image)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.imwrite(\"pano.png\", stitched_image)\n",
    "    image0 = stitched_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcd05cb1438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image0[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\n",
      "Reading images from  /home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Train/Set1\n",
      "Found  ['1.jpg', '2.jpg', '3.jpg']\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  450 , height =  600\n",
      "width =  450 , height =  600\n",
      "all corner 1 len =  616\n",
      "all corner 2 len =  711\n",
      "matched pairs num =  517\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  212\n",
      "inbuilt =  [[-6.51661112e-01 -2.28634018e+00  6.49829969e+02]\n",
      " [-1.86012425e-01 -6.53463614e-01  1.85314843e+02]\n",
      " [-9.86728387e-04 -3.54897705e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.14876920e+00  1.01067548e-01 -4.57489838e+01]\n",
      " [ 2.06516127e-02  1.17943092e+00 -2.76592555e+02]\n",
      " [ 4.36085419e-05  3.83237396e-04  1.00000000e+00]]\n",
      "shapes\n",
      "(450, 600, 3)\n",
      "(450, 600, 3)\n",
      "transformed points =  [[[-4.5748985e+01 -2.7659256e+02]]\n",
      "\n",
      " [[-2.2908066e-01  2.1676820e+02]]\n",
      "\n",
      " [[ 5.7482086e+02  2.2237398e+02]]\n",
      "\n",
      " [[ 6.2710425e+02 -2.5746500e+02]]]\n",
      "min, max\n",
      "-45 -276\n",
      "627 450\n",
      "processing image  2\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  726 , height =  672\n",
      "width =  450 , height =  600\n",
      "all corner 1 len =  830\n",
      "all corner 2 len =  852\n",
      "matched pairs num =  811\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  213\n",
      "inbuilt =  [[ 1.84425152e-02 -1.05099717e+00  3.61242932e+02]\n",
      " [ 8.00094755e-03 -4.52353071e-01  1.55140687e+02]\n",
      " [ 4.95161185e-05 -2.90950308e-03  1.00000000e+00]]\n",
      "Computed =  [[ 8.10970469e-01  5.58837930e-03  1.96457888e+02]\n",
      " [-5.64712883e-02  9.24666825e-01 -2.34946920e+02]\n",
      " [-2.82037822e-04 -4.63782193e-06  1.00000000e+00]]\n",
      "shapes\n",
      "(726, 672, 3)\n",
      "(450, 600, 3)\n",
      "transformed points =  [[[ 196.45789 -234.94691]]\n",
      "\n",
      " [[ 201.19247  437.83542]]\n",
      "\n",
      " [[ 923.6575   493.63245]]\n",
      "\n",
      " [[ 914.8143  -336.71255]]]\n",
      "min, max\n",
      "0 -336\n",
      "923 493\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
