{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/evn python\n",
    "\n",
    "\"\"\"\n",
    "CMSC733 Spring 2019: Classical and Deep Learning Approaches for\n",
    "Geometric Computer Vision\n",
    "Project1: MyAutoPano: Phase 1 Starter Code\n",
    "\n",
    "Author(s): \n",
    "Chahat Deep Singh (chahat@terpmail.umd.edu) \n",
    "PhD Student in Computer Science,\n",
    "University of Maryland, College Park\n",
    "\n",
    "Nitin J. Sanket (nitinsan@terpmail.umd.edu)\n",
    "PhD Candidate in Computer Science,\n",
    "University of Maryland, College Park\n",
    "\"\"\"\n",
    "\n",
    "#Code starts here:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.feature import peak_local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImageSet(folder_name):\n",
    "    print(\"Reading images from \", folder_name)\n",
    "    images = []\n",
    "    files = os.listdir(folder_name)\t\n",
    "    files = sorted(files)\n",
    "    print(\"Found \", files)\n",
    "    for file in files:\n",
    "        image_path = folder_name + \"/\" + file\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            images.append(image)\t\t\t\n",
    "        else:\n",
    "            print(\"Error in loading image \", image)\n",
    "\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImages(image_array, name):\n",
    "\n",
    "    image_array = makeImageSizeSame(image_array)\n",
    "    concat = image_array[0].copy()\n",
    "\n",
    "    for l in range(1,len(image_array)):\n",
    "        image = image_array[l]\n",
    "        concat = np.concatenate((concat,image), axis = 1)\n",
    "        \n",
    "    cv2.imshow(name, concat)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCorners(images, choice):\n",
    "    print(\"detecting corners ...\")\n",
    "    detected_corners = []\n",
    "    cmaps = []\n",
    "    corner_images = []\n",
    "    for i in images:\n",
    "        image = i.copy()\n",
    "        gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        gray_image = np.float32(gray_image)\n",
    "\n",
    "\n",
    "        if(choice == 1):\n",
    "            print(\"using Harris corner detection method.\")\n",
    "            corner_strength = cv2.cornerHarris(gray_image,2,3,0.04)\n",
    "            corner_strength[corner_strength<0.01*corner_strength.max()] = 0\n",
    "            detected_corner = np.where(corner_strength>0.001*corner_strength.max())\n",
    "            detected_corners.append(detected_corner)\n",
    "            cmaps.append(corner_strength)\n",
    "            image[corner_strength > 0.001*corner_strength.max()]=[0,0,255]\n",
    "            corner_images.append(image)\n",
    "        else:\n",
    "            print(\"using Shi-Tomashi corner detection method.\")\n",
    "            dst = cv2.goodFeaturesToTrack(gray_image, 1000 ,0.01, 10)\n",
    "            dst = np.int0(dst)\n",
    "            detected_corners.append(dst)\n",
    "            for c in dst:\n",
    "                x,y = c.ravel()\n",
    "                cv2.circle(image,(x,y),3,(0, 0, 255),-1) \n",
    "                          \n",
    "            corner_images.append(image)\n",
    "            cmap = np.zeros(gray_image.shape) #not sure what to do\n",
    "            cmaps.append(cmap)\n",
    "    #filter detected corners\n",
    "    #remove the corner one\n",
    "    return detected_corners, cmaps, corner_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureDescriptor(gray_image,x,y, patch_size=40):\n",
    "    patch = gray_image[x-patch_size//2:x+patch_size//2, y-patch_size//2:y+patch_size//2] \n",
    "    # gaussian blur\n",
    "    patch = cv2.GaussianBlur(patch,(3,3),0)\n",
    "    # subsample to 20% size or 1/5th\n",
    "    patch = cv2.resize(patch, None, fx=0.2, fy=0.2, interpolation = cv2.INTER_CUBIC)\n",
    "    feature = patch.reshape(-1)\n",
    "    feature = (feature-feature.mean())/ np.std(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPairs(image_1, image_2, all_corners_1, all_corners_2, patch_size = 40, alpha = 0.8):\n",
    "\n",
    "    gray_image1 = cv2.cvtColor(image_1,cv2.COLOR_BGR2GRAY)\n",
    "    gray_image2 = cv2.cvtColor(image_2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    width1, height1 = image_1.shape[:2]\n",
    "    width2, height2 = image_2.shape[:2]\n",
    "\n",
    "    print(\"width = \", width1, \", height = \", height1)\n",
    "    print(\"width = \", width2, \", height = \", height2)\n",
    "\n",
    "    features_1,features_2 = [], []\n",
    "    corners_1, corners_2 = [],[]\n",
    "\n",
    "    print(\"all corner 1 len = \", len(all_corners_1))\n",
    "    print(\"all corner 2 len = \", len(all_corners_2))\n",
    "    \n",
    "    for corner in all_corners_1:\n",
    "        x,y = corner.ravel()\n",
    "        \n",
    "        if (x - (patch_size / 2) > 0) & (x + (patch_size / 2) < height1) & (y - (patch_size / 2) > 0) & (y + (patch_size / 2) < width1):\n",
    "            features_1.append(getFeatureDescriptor(gray_image1, y,x)) \n",
    "            corners_1.append([x,y])\n",
    "        else:\n",
    "            #print(\"ignored x, y\", x, y)\n",
    "            pass\n",
    "\n",
    "    for corner in all_corners_2:\n",
    "        x,y = corner.ravel()\n",
    "        if (x - (patch_size / 2) > 0) & (x + (patch_size / 2) < height2) & (y - (patch_size / 2) > 0) & (y + (patch_size / 2) < width2):\n",
    "            features_2.append(getFeatureDescriptor(gray_image2, y,x)) \n",
    "            corners_2.append([x,y]) \n",
    "\n",
    "    matched_pairs, match_level = [], []\n",
    "    for i, feat_1 in enumerate(features_1):\n",
    "        ssd = []  \n",
    "        for j, feat_2 in enumerate(features_2):\n",
    "            ssd.append(np.sum((feat_1 - feat_2)**2))\n",
    "        top_matche = np.argmin(ssd)\n",
    "        #if ssd[top_matches[0]] / ssd[top_matches[1]] < alpha:   \n",
    "            #matched_pairs.append([corners_1[i] , corners_2[top_matches[0]]])\n",
    "        matched_pairs.append([corners_1[i] , corners_2[top_matche]]) \n",
    "    print(\"matched pairs num = \", len(matched_pairs))\n",
    "    matched_pairs = np.array(matched_pairs)\n",
    "    return matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImageSizeSame(images):\n",
    "    sizes = []\n",
    "    for image in images:\n",
    "        x, y, ch = image.shape\n",
    "        sizes.append([x, y, ch])\n",
    "\n",
    "    sizes = np.array(sizes)\n",
    "    x_target, y_target, _ = np.max(sizes, axis = 0)\n",
    "    \n",
    "    images_resized = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image_resized = np.zeros((x_target, y_target, sizes[i, 2]), np.uint8)\n",
    "        image_resized[0:sizes[i, 0], 0:sizes[i, 1], 0:sizes[i, 2]] = image\n",
    "        images_resized.append(image_resized)\n",
    "\n",
    "    return images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMatches(image_1, image_2, matched_pairs, partition_width = 20):\n",
    "\n",
    "    image_1, image_2 = makeImageSizeSame([image_1, image_2])\n",
    "\n",
    "    concat = np.concatenate((image_1, image_2), axis = 1)\n",
    "    corners_1 = matched_pairs[:,0].copy()\n",
    "    corners_2  = matched_pairs[:,1].copy()\n",
    "    corners_2[:,0] += image_1.shape[1]\n",
    "\n",
    "    for (x1,y1) , (x2,y2) in zip(corners_1, corners_2):\n",
    "        cv2.line(concat, (x1,y1), (x2,y2), (0, 0, 255), 1)\n",
    "    \n",
    "      \n",
    "    cv2.imshow('Feature_matches', concat)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testShowMatches(image_1, image_2, partition_width = 20):\n",
    "    matched_pairs= []\n",
    "    I = np.linspace(10, 100, 10)\n",
    "    for i in I:\n",
    "        x1 = i\n",
    "        y1 = i\n",
    "        corner1 = np.int0(np.array([x1, y1]))\n",
    "\n",
    "        x2 = i\n",
    "        y2 = i\n",
    "        corner2 = np.int0(np.array([x2, y2]))\n",
    "        matched_pairs.append([corner1 , corner2])\n",
    "\n",
    "    matched_pairs = np.array(matched_pairs)\n",
    "    showMatches(image_1, image_2, matched_pairs, partition_width = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutliers(matched_pairs, outliers, accuracy, thresh):\n",
    "\n",
    "    set1 = matched_pairs[:, 0]\n",
    "    set2 = matched_pairs[:, 1]\n",
    "\n",
    "    N_best = 0\n",
    "    H_best = np.zeros([3, 3])\n",
    "    \n",
    "    e = outliers / set1.shape[0]\n",
    "    s = 4\n",
    "    p = accuracy\n",
    "    iterations = np.log(1 - p) / np.log(1 - np.power((1 - e), s))\n",
    "    iterations = np.int(iterations)\n",
    "    iterations = 4000\n",
    "\n",
    "    filtered_pair_indices = []\n",
    "\n",
    "    print(\"iterations = \", iterations)\n",
    "    for i in range(iterations):\n",
    "        #randomly select four points\n",
    "        n_rows = set1.shape[0]\n",
    "        random_indices = np.random.choice(n_rows, size=4)\n",
    "\n",
    "        set1_random = set1[random_indices]\n",
    "        set2_random = set2[random_indices]\n",
    "              \n",
    "        #compute homography\n",
    "        H = cv2.getPerspectiveTransform(np.float32(set1_random), np.float32(set2_random))\n",
    "\n",
    "        set1_dash = np.vstack((set1[:,0], set1[:,1], np.ones([1, n_rows])))\n",
    "        set1_transformed_dash = np.dot(H, set1_dash)\n",
    "        \n",
    "        t1 = set1_transformed_dash[0,:]/set1_transformed_dash[2,:]\n",
    "        t2 = set1_transformed_dash[1,:]/set1_transformed_dash[2,:]\n",
    "\n",
    "        set1_transformed = np.array([t1, t2]).T\n",
    "        #print(set1_transformed.shape)\n",
    "\n",
    "        E = calculateError(set2, set1_transformed)\n",
    "        \n",
    "     \n",
    "        E[E <= thresh] = 1\n",
    "        E[E > thresh] = 0\n",
    "    \n",
    "    \n",
    "        N = np.sum(E)\n",
    "\n",
    "\n",
    "        if N > N_best:\n",
    "            N_best = N\n",
    "            H_best = H\n",
    "            filtered_pair_indices = np.where(E == 1)\n",
    "    \n",
    "    filtered_set1 =  set1[filtered_pair_indices]\n",
    "    filtered_set2 =  set2[filtered_pair_indices]\n",
    "\n",
    "    print(\"Number of pairs after filtering = \", filtered_set1.shape[0])\n",
    "\n",
    "    filter_matched_pairs = np.zeros([filtered_set1.shape[0], filtered_set1.shape[1], 2])\n",
    "\n",
    "    filter_matched_pairs[:, 0, :] = filtered_set1\n",
    "    filter_matched_pairs[:, 1, :] = filtered_set2\n",
    "\n",
    "    filter_matched_pairs = filter_matched_pairs.astype(int)\n",
    "\n",
    "    H_inbuit, _ = cv2.findHomography(set1, set2)\n",
    "    print(\"inbuilt = \", H_inbuit)\n",
    "    print(\"Computed = \", H_best)\n",
    "\n",
    "    return H_best, filter_matched_pairs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateError(set1, set2):\n",
    "   \n",
    "    E = np.zeros(set1.shape[0])\n",
    "    tmp = set2 - set1\n",
    "    num = set1.shape[0]\n",
    "\n",
    "    for n in range(num):\n",
    "        E[n] = np.linalg.norm(tmp[n])\n",
    "    return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaptiveNonMaximalSuppression(images, C_maps, N_best):\n",
    "\n",
    "    anms_img = []\n",
    "    anms_corners = []\n",
    "    for i,image in enumerate(images):\n",
    "\n",
    "        cmap = C_maps[i]\n",
    "        local_maximas = peak_local_max(cmap, min_distance=10)\n",
    "        n_strong = local_maximas.shape[0]\n",
    "        \n",
    "        r = [np.Infinity for i in range(n_strong)]\n",
    "        x=np.zeros((n_strong,1))\n",
    "        y=np.zeros((n_strong,1))\n",
    "        eu_dist = 0\n",
    "\n",
    "        for i in range(n_strong):\n",
    "            for j in range(n_strong):\n",
    "                x_j = local_maximas[j][0]\n",
    "                y_j = local_maximas[j][1]\n",
    "\n",
    "                x_i = local_maximas[i][0]\n",
    "                y_i = local_maximas[i][1]\n",
    "\n",
    "                if(cmap[x_j, y_j] > cmap[x_i, y_i]):\n",
    "                    eu_dist = np.square(x_j - x_i) + np.square(y_j - y_i)\n",
    "                if r[i] > eu_dist:\n",
    "                    r[i] = eu_dist\n",
    "                    x[i] = x_j\n",
    "                    y[i] = y_j\n",
    "\n",
    "        index = np.argsort(r)\n",
    "        index = np.flip(index)\n",
    "        index = index[0:N_best]\n",
    "        x_best=np.zeros((N_best,1))\n",
    "        y_best=np.zeros((N_best,1))\n",
    "\n",
    "        for i in range(N_best):\n",
    "            x_best[i] = np.int0(x[index[i]])\n",
    "            y_best[i] = np.int0(y[index[i]]) \n",
    "            cv2.circle(image, (y_best[i], x_best[i]), 3, (0, 255, 0), -1)\n",
    "\n",
    "        anms_corner = np.int0(np.concatenate((x_best, y_best), axis = 1))\n",
    "        anms_corners.append(anms_corner)\n",
    "        anms_img.append(image)\n",
    "    return anms_corners, anms_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitchImagePairs(image0, image1, H):\n",
    "\n",
    "    #stitch image 0 on image 1\n",
    "    print(\"shapes\")\n",
    "    print(image0.shape)\n",
    "    print(image1.shape)\n",
    "    \n",
    "\n",
    "    h0 ,w0 ,_ = image0.shape\n",
    "    h1 ,w1 ,_ = image1.shape\n",
    "\n",
    "    points_on_image0 = np.float32([[0, 0], [0, h0], [w0, h0], [w0, 0]]).reshape(-1,1,2)\n",
    "    points_on_image0_transformed = cv2.perspectiveTransform(points_on_image0, H)\n",
    "    print(\"transformed points = \", points_on_image0_transformed)\n",
    "    points_on_image1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1,1,2)\n",
    "\n",
    "    points_on_merged_images = np.concatenate((points_on_image0_transformed, points_on_image1), axis = 0)\n",
    "    points_on_merged_images_ = []\n",
    "\n",
    "    for p in range(len(points_on_merged_images)):\n",
    "        points_on_merged_images_.append(points_on_merged_images[p].ravel())\n",
    "\n",
    "    points_on_merged_images_ = np.array(points_on_merged_images_)\n",
    "\n",
    "    x_min, y_min = np.int0(np.min(points_on_merged_images_, axis = 0))\n",
    "    x_max, y_max = np.int0(np.max(points_on_merged_images_, axis = 0))\n",
    "\n",
    "    print(\"min, max\")\n",
    "    print(x_min, y_min)\n",
    "    print(x_max, y_max)\n",
    "\n",
    "    # overlap_area = cv2.polylines(image1,[np.int32(points_on_image0_transformed)],True,255,3, cv2.LINE_AA) \n",
    "    # cv2.imshow(\"original_image_overlapping.jpg\", overlap_area)\n",
    "    # cv2.waitKey() \n",
    "    # cv2.destroyAllWindows()\n",
    "    H_translate = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]]) # translate\n",
    "\n",
    "    image0_transformed = cv2.warpPerspective(image0, np.dot(H_translate, H), (x_max-x_min, y_max-y_min))\n",
    "    image0_transformed[-y_min:-y_min+h1, -x_min: -x_min+w1] = image1\n",
    "    return(image0_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitchImageArray(image_array, H_array):\n",
    "    \n",
    "    N = len(image_array)\n",
    "\n",
    "    target_image = image_array[N-1]\n",
    "\n",
    "    ht, wt, _ = target_image.shape\n",
    "    points_on_target_image = np.float32([[0, 0], [0, ht], [wt, ht], [wt, 0]]).reshape(-1,1,2)\n",
    "\n",
    "    points = points_on_target_image\n",
    "    \n",
    "    images_transformed = []\n",
    "    H_translate_array = []\n",
    "\n",
    "    for n in range(N-1):\n",
    "        image = image_array[n]\n",
    "        h, w, _ = image.shape\n",
    "        points_on_image = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1,1,2)\n",
    "\n",
    "        points_on_image_transformed = points_on_image \n",
    "        for m in range(n, N-1):\n",
    "            H = H_array[m]\n",
    "            points_on_image_transformed = cv2.perspectiveTransform(points_on_image_transformed, H)\n",
    "        \n",
    "        points = np.concatenate((points, points_on_image_transformed), axis = 0)\n",
    "\n",
    "    points_ = []\n",
    "    for p in range(len(points)):\n",
    "        points_.append(points[p].ravel())\n",
    "\n",
    "    points_ = np.array(points_)\n",
    "\n",
    "    x_min, y_min = np.int0(np.min(points_, axis = 0))\n",
    "    x_max, y_max = np.int0(np.max(points_, axis = 0))\n",
    "\n",
    "    H_translate = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]]) # translate\n",
    "\n",
    "    for n in range(N-1):\n",
    "        image = image_array[n]\n",
    "        image_transformed = image\n",
    "        for m in range(n, N-1):\n",
    "            H = H_array[m]\n",
    "            image_transformed = cv2.warpPerspective(image_transformed, np.dot(H_translate,H), (x_max-x_min, y_max-y_min))\n",
    "\n",
    "        #image_transformed = cv2.warpAffine(image_transformed, H_translate, (x_max-x_min, y_max-y_min))\n",
    "        images_transformed.append(image_transformed)\n",
    "\n",
    "    final_output = np.zeros((y_max-y_min, x_max-x_min, 3), np.uint8)\n",
    "    for i in range(len(images_transformed)):\n",
    "        final_output = final_output + images_transformed[i]\n",
    "\n",
    "    return images_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Add any Command Line arguments here\n",
    "    # Parser = argparse.ArgumentParser()\n",
    "    # Parser.add_argument('--NumFeatures', default=100, help='Number of best features to extract from each image, Default:100')\n",
    "    \n",
    "    # Args = Parser.parse_args()\n",
    "    # NumFeatures = Args.NumFeatures\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Read a set of images for Panorama stitching\n",
    "    \"\"\"\n",
    "    print(\"main\")\n",
    "    folder_name = \"/home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Train/Set1\"\n",
    "    use_harris = False\n",
    "    images = readImageSet(folder_name)\n",
    "    displayImages(images, \"image_set\")\n",
    "    N_images = len(images)\n",
    "\n",
    "    choice = 2\n",
    "    if use_harris:\n",
    "        choice = 1\n",
    "\n",
    "    image0 = images[0]\n",
    "\n",
    "    for i in range(1, N_images):\n",
    "\n",
    "        print(\"processing image \", i)\n",
    "        image1 = images[i] \n",
    "\n",
    "        image_pair = [image0, image1]\n",
    "        \n",
    "        detected_corners, cmaps, corner_images = detectCorners(image_pair, choice)\n",
    "        displayImages(corner_images, \"corners\")\n",
    "        \"\"\"\n",
    "        Perform ANMS: Adaptive Non-Maximal Suppression\n",
    "        Save ANMS output as anms.png\n",
    "        \"\"\"\n",
    "        if (choice == 1):\n",
    "            print(\"Applying ALMS.\")\n",
    "            detected_corners, anms_image = AdaptiveNonMaximalSuppression(image_pair, cmaps, 500)\n",
    "            displayImages(anms_image, \"anms_output\")\n",
    "        else:\n",
    "            print(\"goodFeaturesToTrack is already using ALMS.\") #review\n",
    "\n",
    "        detected_corners0 = detected_corners[0]\n",
    "        detected_corners1 = detected_corners[1]\n",
    "            \n",
    "        matched_pairs = getPairs(image0, image1, detected_corners0, detected_corners1, patch_size = 40, alpha = 0.9 )\n",
    "        showMatches(image0, image1, matched_pairs, partition_width = 20)\n",
    "        \"\"\"\n",
    "        Refine: RANSAC, Estimate Homography\n",
    "        \"\"\"\n",
    "        H,filtered_matched_pairs = filterOutliers(matched_pairs, 20, 0.9, 5)\n",
    "        showMatches(image0, image1, filtered_matched_pairs, partition_width = 20)\n",
    "        \"\"\"\n",
    "        Image Warping + Blending\n",
    "        Save Panorama output as mypano.png\n",
    "        \"\"\"\n",
    "        stitched_image = stitchImagePairs(image0, image1, H)\n",
    "        cv2.imshow(\"pano.jpg\", stitched_image)\n",
    "        cv2.waitKey() \n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.imwrite(\"Results/pano.png\", stitched_image)\n",
    "        image0 = stitched_image\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "main\n",
      "Reading images from  /home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Train/Set1\n",
      "Found  ['1.jpg', '2.jpg', '3.jpg']\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  450 , height =  600\n",
      "width =  450 , height =  600\n",
      "all corner 1 len =  616\n",
      "all corner 2 len =  711\n",
      "matched pairs num =  517\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  212\n",
      "inbuilt =  [[-6.51661112e-01 -2.28634018e+00  6.49829969e+02]\n",
      " [-1.86012425e-01 -6.53463614e-01  1.85314843e+02]\n",
      " [-9.86728387e-04 -3.54897705e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.14117538e+00  1.00295222e-01 -4.45012977e+01]\n",
      " [ 1.56297848e-02  1.15818181e+00 -2.68742151e+02]\n",
      " [ 1.95599725e-05  3.87205958e-04  1.00000000e+00]]\n",
      "shapes\n",
      "(450, 600, 3)\n",
      "(450, 600, 3)\n",
      "transformed points =  [[[-4.4501297e+01 -2.6874216e+02]]\n",
      "\n",
      " [[ 5.3783804e-01  2.1498083e+02]]\n",
      "\n",
      " [[ 5.7786603e+02  2.2076074e+02]]\n",
      "\n",
      " [[ 6.3277765e+02 -2.5635568e+02]]]\n",
      "min, max\n",
      "-44 -268\n",
      "632 450\n",
      "processing image  2\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  718 , height =  676\n",
      "width =  450 , height =  600\n",
      "all corner 1 len =  832\n",
      "all corner 2 len =  852\n",
      "matched pairs num =  809\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  215\n",
      "inbuilt =  [[-5.10146797e-02 -1.00977314e+00  3.57316714e+02]\n",
      " [-2.20675904e-02 -4.30825426e-01  1.52507969e+02]\n",
      " [-1.46956529e-04 -2.82136915e-03  1.00000000e+00]]\n",
      "Computed =  [[ 8.19934344e-01  2.78641016e-02  1.91262853e+02]\n",
      " [-6.22196133e-02  9.60231095e-01 -2.38929617e+02]\n",
      " [-3.09844332e-04  4.17590526e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(718, 676, 3)\n",
      "(450, 600, 3)\n",
      "transformed points =  [[[ 191.26285 -238.92961]]\n",
      "\n",
      " [[ 205.11919  437.4017 ]]\n",
      "\n",
      " [[ 932.9903   497.7962 ]]\n",
      "\n",
      " [[ 943.0687  -355.43832]]]\n",
      "min, max\n",
      "0 -355\n",
      "943 497\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}