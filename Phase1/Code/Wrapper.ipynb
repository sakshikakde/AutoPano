{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/evn python\n",
    "\n",
    "\"\"\"\n",
    "CMSC733 Spring 2019: Classical and Deep Learning Approaches for\n",
    "Geometric Computer Vision\n",
    "Project1: MyAutoPano: Phase 1 Starter Code\n",
    "\n",
    "Author(s): \n",
    "Chahat Deep Singh (chahat@terpmail.umd.edu) \n",
    "PhD Student in Computer Science,\n",
    "University of Maryland, College Park\n",
    "\n",
    "Nitin J. Sanket (nitinsan@terpmail.umd.edu)\n",
    "PhD Candidate in Computer Science,\n",
    "University of Maryland, College Park\n",
    "\"\"\"\n",
    "\n",
    "#Code starts here:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.feature import peak_local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImageSet(folder_name):\n",
    "    print(\"Reading images from \", folder_name)\n",
    "    images = []\n",
    "    files = os.listdir(folder_name)\t\n",
    "    files = sorted(files)\n",
    "    print(\"Found \", files)\n",
    "    for file in files:\n",
    "        image_path = folder_name + \"/\" + file\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            images.append(image)\t\t\t\n",
    "        else:\n",
    "            print(\"Error in loading image \", image)\n",
    "\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImages(image_array, name):\n",
    "\n",
    "    concat = image_array[0]\n",
    "    print(concat.shape)\n",
    "    for l in range(1,len(image_array)):\n",
    "        concat = np.concatenate((concat, image_array[l]), axis = 1)\n",
    "    cv2.imshow(name, concat)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCorners(images, choice):\n",
    "    print(\"detecting corners ...\")\n",
    "    detected_corners = []\n",
    "    cmaps = []\n",
    "    corner_images = []\n",
    "    for image in images:\n",
    "        gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        gray_image = np.float32(gray_image)\n",
    "\n",
    "\n",
    "        if(choice == 1):\n",
    "            print(\"using Harris corner detection method.\")\n",
    "            corner_strength = cv2.cornerHarris(gray_image,2,3,0.04)\n",
    "            corner_strength[corner_strength<0.01*corner_strength.max()] = 0\n",
    "            detected_corner = np.where(corner_strength>0.001*corner_strength.max())\n",
    "            detected_corners.append(detected_corner)\n",
    "            cmaps.append(corner_strength)\n",
    "            image[corner_strength > 0.001*corner_strength.max()]=[0,0,255]\n",
    "            corner_images.append(image)\n",
    "        else:\n",
    "            print(\"using Shi-Tomashi corner detection method.\")\n",
    "            dst = cv2.goodFeaturesToTrack(gray_image, 250 ,0.01, 10)\n",
    "            dst = np.int0(dst)\n",
    "            detected_corners.append(dst)\n",
    "            for c in dst:\n",
    "                x,y = c.ravel()\n",
    "                cv2.circle(image,(x,y),3,(0, 0, 255),-1) \n",
    "                          \n",
    "            corner_images.append(image)\n",
    "            cmap = np.zeros(gray_image.shape) #not sure what to do\n",
    "            cmaps.append(cmap)\n",
    "\n",
    "    return detected_corners, cmaps, corner_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureDescriptor(gray_image,x,y, patch_size=40):\n",
    "    patch = gray_image[x-patch_size//2:x+patch_size//2, y-patch_size//2:y+patch_size//2] \n",
    "    # gaussian blur\n",
    "    patch = cv2.GaussianBlur(patch,(3,3),0)\n",
    "    # subsample to 20% size or 1/5th\n",
    "    patch = cv2.resize(patch, None, fx=0.2, fy=0.2, interpolation = cv2.INTER_CUBIC)\n",
    "    feature = patch.reshape(-1)\n",
    "    feature = (feature-feature.mean())/ np.std(feature)\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPairs(image_1, image_2, all_corners_1, all_corners_2, patch_size = 40, alpha = 0.8):\n",
    "\n",
    "    gray_image1 = cv2.cvtColor(image_1,cv2.COLOR_BGR2GRAY)\n",
    "    gray_image2 = cv2.cvtColor(image_2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    width, height = image_1.shape[:2]\n",
    "    print(\"width = \", width, \", height = \", height)\n",
    "    features_1,features_2 = [], []\n",
    "    corners_1, corners_2 = [],[]\n",
    "\n",
    "    print(\"all corner 1 len = \", len(all_corners_1))\n",
    "    print(\"all corner 2 len = \", len(all_corners_2))\n",
    "    \n",
    "    for corner in all_corners_1:\n",
    "        x,y = corner.ravel()\n",
    "        \n",
    "        if (x - (patch_size / 2) > 0) & (x + (patch_size / 2) < height) & (y - (patch_size / 2) > 0) & (y + (patch_size / 2) < width):\n",
    "            features_1.append(getFeatureDescriptor(gray_image1, y,x)) \n",
    "            corners_1.append([x,y])\n",
    "        else:\n",
    "            #print(\"ignored x, y\", x, y)\n",
    "            pass\n",
    "\n",
    "    for corner in all_corners_2:\n",
    "        x,y = corner.ravel()\n",
    "        if (x - (patch_size / 2) > 0) & (x + (patch_size / 2) < height) & (y - (patch_size / 2) > 0) & (y + (patch_size / 2) < width):\n",
    "            features_2.append(getFeatureDescriptor(gray_image2, y,x)) \n",
    "            corners_2.append([x,y]) \n",
    "\n",
    "    matched_pairs, match_level = [], []\n",
    "    for i, feat_1 in enumerate(features_1):\n",
    "        ssd = []  \n",
    "        for j, feat_2 in enumerate(features_2):\n",
    "            ssd.append(np.sum((feat_1 - feat_2)**2))\n",
    "        top_matche = np.argmin(ssd)\n",
    "        #if ssd[top_matches[0]] / ssd[top_matches[1]] < alpha:   \n",
    "            #matched_pairs.append([corners_1[i] , corners_2[top_matches[0]]])\n",
    "        matched_pairs.append([corners_1[i] , corners_2[top_matche]]) \n",
    "    print(\"matched pairs num = \", len(matched_pairs))\n",
    "    matched_pairs = np.array(matched_pairs)\n",
    "    return matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMatches(image_1, image_2, matched_pairs, partition_width = 20):\n",
    "    \n",
    "\n",
    "    concat = np.concatenate((image_1, image_2), axis = 1)\n",
    "    corners_1 = matched_pairs[:,0].copy()\n",
    "    corners_2  = matched_pairs[:,1].copy()\n",
    "    corners_2[:,0] += image_1.shape[1]\n",
    "\n",
    "    for (x1,y1) , (x2,y2) in zip(corners_1, corners_2):\n",
    "        cv2.line(concat, (x1,y1), (x2,y2), (0, 0, 255), 1)\n",
    "    \n",
    "      \n",
    "    cv2.imshow('Feature_matches', concat)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testShowMatches(image_1, image_2, partition_width = 20):\n",
    "    matched_pairs= []\n",
    "    I = np.linspace(10, 100, 10)\n",
    "    for i in I:\n",
    "        x1 = i\n",
    "        y1 = i\n",
    "        corner1 = np.int0(np.array([x1, y1]))\n",
    "\n",
    "        x2 = i\n",
    "        y2 = i\n",
    "        corner2 = np.int0(np.array([x2, y2]))\n",
    "        matched_pairs.append([corner1 , corner2])\n",
    "\n",
    "    matched_pairs = np.array(matched_pairs)\n",
    "    showMatches(image_1, image_2, matched_pairs, partition_width = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutliers(matched_pairs, outliers, accuracy, thresh):\n",
    "\n",
    "    set1 = matched_pairs[:, 0]\n",
    "    set2 = matched_pairs[:, 1]\n",
    "\n",
    "    N_best = 0\n",
    "    H_best = np.zeros([3, 3])\n",
    "    \n",
    "    e = outliers / set1.shape[0]\n",
    "    s = 4\n",
    "    p = accuracy\n",
    "    iterations = np.log(1 - p) / np.log(1 - np.power((1 - e), s))\n",
    "    iterations = np.int(iterations)\n",
    "    iterations = 4000\n",
    "\n",
    "    filtered_pair_indices = []\n",
    "\n",
    "    print(\"iterations = \", iterations)\n",
    "    for i in range(iterations):\n",
    "        #randomly select four points\n",
    "        n_rows = set1.shape[0]\n",
    "        random_indices = np.random.choice(n_rows, size=4)\n",
    "\n",
    "        set1_random = set1[random_indices]\n",
    "        set2_random = set2[random_indices]\n",
    "              \n",
    "        #compute homography\n",
    "        H = cv2.getPerspectiveTransform(np.float32(set1_random), np.float32(set2_random))\n",
    "\n",
    "        set1_dash = np.vstack((set1[:,0], set1[:,1], np.ones([1, n_rows])))\n",
    "        set1_transformed_dash = np.dot(H, set1_dash)\n",
    "        \n",
    "        t1 = set1_transformed_dash[0,:]/set1_transformed_dash[2,:]\n",
    "        t2 = set1_transformed_dash[1,:]/set1_transformed_dash[2,:]\n",
    "\n",
    "        set1_transformed = np.array([t1, t2]).T\n",
    "        #print(set1_transformed.shape)\n",
    "\n",
    "        E = calculateError(set2, set1_transformed)\n",
    "        \n",
    "     \n",
    "        E[E <= thresh] = 1\n",
    "        E[E > thresh] = 0\n",
    "    \n",
    "    \n",
    "        N = np.sum(E)\n",
    "\n",
    "\n",
    "        if N > N_best:\n",
    "            N_best = N\n",
    "            H_best = H\n",
    "            filtered_pair_indices = np.where(E == 1)\n",
    "    \n",
    "    filtered_set1 =  set1[filtered_pair_indices]\n",
    "    filtered_set2 =  set2[filtered_pair_indices]\n",
    "\n",
    "    print(\"Number of pairs after filtering = \", filtered_set1.shape[0])\n",
    "\n",
    "    filter_matched_pairs = np.zeros([filtered_set1.shape[0], filtered_set1.shape[1], 2])\n",
    "\n",
    "    filter_matched_pairs[:, 0, :] = filtered_set1\n",
    "    filter_matched_pairs[:, 1, :] = filtered_set2\n",
    "\n",
    "    filter_matched_pairs = filter_matched_pairs.astype(int)\n",
    "\n",
    "    H_inbuit, _ = cv2.findHomography(set1, set2)\n",
    "    print(\"inbuilt = \", H_inbuit)\n",
    "    print(\"Computed = \", H_best)\n",
    "\n",
    "    return H_best, filter_matched_pairs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateError(set1, set2):\n",
    "   \n",
    "    E = np.zeros(set1.shape[0])\n",
    "    tmp = set2 - set1\n",
    "    num = set1.shape[0]\n",
    "\n",
    "    for n in range(num):\n",
    "        E[n] = np.linalg.norm(tmp[n])\n",
    "    return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaptiveNonMaximalSuppression(images, C_maps, N_best):\n",
    "\n",
    "    anms_img = []\n",
    "    anms_corners = []\n",
    "    for i,image in enumerate(images):\n",
    "\n",
    "        cmap = C_maps[i]\n",
    "        local_maximas = peak_local_max(cmap, min_distance=10)\n",
    "        n_strong = local_maximas.shape[0]\n",
    "        \n",
    "        r = [np.Infinity for i in range(n_strong)]\n",
    "        x=np.zeros((n_strong,1))\n",
    "        y=np.zeros((n_strong,1))\n",
    "        eu_dist = 0\n",
    "\n",
    "        for i in range(n_strong):\n",
    "            for j in range(n_strong):\n",
    "                x_j = local_maximas[j][0]\n",
    "                y_j = local_maximas[j][1]\n",
    "\n",
    "                x_i = local_maximas[i][0]\n",
    "                y_i = local_maximas[i][1]\n",
    "\n",
    "                if(cmap[x_j, y_j] > cmap[x_i, y_i]):\n",
    "                    eu_dist = np.square(x_j - x_i) + np.square(y_j - y_i)\n",
    "                if r[i] > eu_dist:\n",
    "                    r[i] = eu_dist\n",
    "                    x[i] = x_j\n",
    "                    y[i] = y_j\n",
    "\n",
    "        index = np.argsort(r)\n",
    "        index = np.flip(index)\n",
    "        index = index[0:N_best]\n",
    "        x_best=np.zeros((N_best,1))\n",
    "        y_best=np.zeros((N_best,1))\n",
    "\n",
    "        for i in range(N_best):\n",
    "            x_best[i] = np.int0(x[index[i]])\n",
    "            y_best[i] = np.int0(y[index[i]]) \n",
    "            cv2.circle(image, (y_best[i], x_best[i]), 3, (0, 255, 0), -1)\n",
    "\n",
    "        anms_corner = np.int0(np.concatenate((x_best, y_best), axis = 1))\n",
    "        anms_corners.append(anms_corner)\n",
    "        anms_img.append(image)\n",
    "    return anms_corners, anms_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Add any Command Line arguments here\n",
    "    # Parser = argparse.ArgumentParser()\n",
    "    # Parser.add_argument('--NumFeatures', default=100, help='Number of best features to extract from each image, Default:100')\n",
    "    \n",
    "    # Args = Parser.parse_args()\n",
    "    # NumFeatures = Args.NumFeatures\n",
    "\n",
    "    \"\"\"\n",
    "    Read a set of images for Panorama stitching\n",
    "    \"\"\"\n",
    "    print(\"main\")\n",
    "    folder_name = \"/home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Train/Set1\"\n",
    "    use_harris = False\n",
    "    images = readImageSet(folder_name)\n",
    "    displayImages(images, \"image_set\")\n",
    "\n",
    "    \"\"\"\n",
    "    Corner Detection\n",
    "    Save Corner detection output as corners.png\n",
    "    1 = harris, 2 = shi-tomashi\n",
    "    \"\"\"\n",
    "    choice = 2\n",
    "    if use_harris:\n",
    "        choice = 1\n",
    "\n",
    "    detected_corners, cmaps, corner_images = detectCorners(images, choice)\n",
    "    displayImages(corner_images, \"corners\")\n",
    "    \"\"\"\n",
    "    Perform ANMS: Adaptive Non-Maximal Suppression\n",
    "    Save ANMS output as anms.png\n",
    "    \"\"\"\n",
    "    if (choice == 1):\n",
    "        print(\"Applying ALMS.\")\n",
    "        detected_corners, anms_image = AdaptiveNonMaximalSuppression(images, cmaps, 500)\n",
    "        displayImages(anms_image, \"anms_output\")\n",
    "    else:\n",
    "        print(\"goodFeaturesToTrack is already using ALMS.\") #review\n",
    "\n",
    "    \"\"\"\n",
    "    Feature Descriptors\n",
    "    Save Feature Descriptor output as FD.png\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Feature Matching\n",
    "    Save Feature Matching output as matching.png\n",
    "    \"\"\"\n",
    "    matched_pairs = getPairs(images[0], images[1], detected_corners[0], detected_corners[1], patch_size = 40, alpha = 0.9 )\n",
    "    showMatches(images[0], images[1], matched_pairs, partition_width = 20)\n",
    "    \"\"\"\n",
    "    Refine: RANSAC, Estimate Homography\n",
    "    \"\"\"\n",
    "    H,filtered_matched_pairs = filterOutliers(matched_pairs, 10, 0.9, 50)\n",
    "    showMatches(images[0], images[1], filtered_matched_pairs, partition_width = 20)\n",
    "    \"\"\"\n",
    "    Image Warping + Blending\n",
    "    Save Panorama output as mypano.png\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "main\n",
      "Reading images from  /home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Train/Set1\n",
      "Found  ['1.jpg', '2.jpg', '3.jpg']\n",
      "(450, 600, 3)\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "(450, 600, 3)\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  450 , height =  600\n",
      "all corner 1 len =  250\n",
      "all corner 2 len =  250\n",
      "matched pairs num =  187\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  94\n",
      "inbuilt =  [[-8.56904928e-01 -1.90951356e+00  6.69680510e+02]\n",
      " [-2.85483403e-01 -6.37184149e-01  2.23443272e+02]\n",
      " [-1.27773234e-03 -2.85677072e-03  1.00000000e+00]]\n",
      "Computed =  [[ 6.75758537e-01 -4.45816202e-02  5.10623149e+01]\n",
      " [-7.79384769e-02  7.58325442e-01 -1.35219424e+02]\n",
      " [-4.82979162e-04 -4.81012849e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "main\n",
      "Reading images from  /home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Train/Set1\n",
      "Found  ['1.jpg', '2.jpg', '3.jpg']\n",
      "(450, 600, 3)\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "(450, 600, 3)\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  450 , height =  600\n",
      "all corner 1 len =  250\n",
      "all corner 2 len =  250\n",
      "matched pairs num =  187\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  52\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b408860bc2c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}