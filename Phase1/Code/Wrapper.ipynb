{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/evn python\n",
    "\n",
    "\"\"\"\n",
    "CMSC733 Spring 2019: Classical and Deep Learning Approaches for\n",
    "Geometric Computer Vision\n",
    "Project1: MyAutoPano: Phase 1 Starter Code\n",
    "\n",
    "Author(s): \n",
    "Chahat Deep Singh (chahat@terpmail.umd.edu) \n",
    "PhD Student in Computer Science,\n",
    "University of Maryland, College Park\n",
    "\n",
    "Nitin J. Sanket (nitinsan@terpmail.umd.edu)\n",
    "PhD Candidate in Computer Science,\n",
    "University of Maryland, College Park\n",
    "\"\"\"\n",
    "\n",
    "#Code starts here:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.feature import peak_local_max\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImageSet(folder_name):\n",
    "    print(\"Reading images from \", folder_name)\n",
    "    images = []\n",
    "    files = os.listdir(folder_name)\t\n",
    "    files = sorted(files)\n",
    "    print(\"Found \", files)\n",
    "    for file in files:\n",
    "        image_path = folder_name + \"/\" + file\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            images.append(image)\t\t\t\n",
    "        else:\n",
    "            print(\"Error in loading image \", image)\n",
    "\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImages(img_array, file_name):\n",
    "    \n",
    "    image_array = img_array.copy()\n",
    "    image_array = makeImageSizeSame(image_array)\n",
    "    concat = image_array[0].copy()\n",
    "\n",
    "    for l in range(1,len(image_array)):\n",
    "        image = image_array[l]\n",
    "        concat = np.concatenate((concat,image), axis = 1)\n",
    "        \n",
    "    cv2.imshow(file_name, concat)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n",
    "    #cv2.imwrite(file_name, concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCorners(imgs, choice):\n",
    "    images = imgs.copy()\n",
    "    print(\"detecting corners ...\")\n",
    "    detected_corners = []\n",
    "    cmaps = []\n",
    "    corner_images = []\n",
    "    for i in images:\n",
    "        image = i.copy()\n",
    "        gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        gray_image = np.float32(gray_image)\n",
    "\n",
    "\n",
    "        if(choice == 1):\n",
    "            print(\"using Harris corner detection method.\")\n",
    "            corner_strength = cv2.cornerHarris(gray_image,2,3,0.04)\n",
    "            corner_strength[corner_strength<0.01*corner_strength.max()] = 0\n",
    "            detected_corner = np.where(corner_strength>0.001*corner_strength.max())\n",
    "            detected_corners.append(detected_corner)\n",
    "            cmaps.append(corner_strength)\n",
    "            image[corner_strength > 0.001*corner_strength.max()]=[0,0,255]\n",
    "            corner_images.append(image)\n",
    "        else:\n",
    "            print(\"using Shi-Tomashi corner detection method.\")\n",
    "            dst = cv2.goodFeaturesToTrack(gray_image, 1000 ,0.01, 10)\n",
    "            dst = np.int0(dst)\n",
    "            detected_corners.append(dst)\n",
    "            for c in dst:\n",
    "                x,y = c.ravel()\n",
    "                cv2.circle(image,(x,y),3,(0, 0, 255),-1) \n",
    "                          \n",
    "            corner_images.append(image)\n",
    "            cmap = np.zeros(gray_image.shape) #not sure what to do\n",
    "            cmaps.append(cmap)\n",
    "    #filter detected corners\n",
    "    #remove the corner one\n",
    "    return detected_corners, cmaps, corner_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureDescriptor(gray_img,x,y, patch_size=40):\n",
    "    gray_image = gray_img\n",
    "    patch = gray_image[x-patch_size//2:x+patch_size//2, y-patch_size//2:y+patch_size//2] \n",
    "    # gaussian blur\n",
    "    patch = cv2.GaussianBlur(patch,(3,3),0)\n",
    "    # subsample to 20% size or 1/5th\n",
    "    patch = cv2.resize(patch, None, fx=0.2, fy=0.2, interpolation = cv2.INTER_CUBIC)\n",
    "    feature = patch.reshape(-1)\n",
    "    feature = (feature-feature.mean())/ np.std(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPairs(img_1, img_2, all_corners_1, all_corners_2, patch_size = 40, alpha = 0.8):\n",
    "\n",
    "    image_1 = img_1.copy()\n",
    "    image_2 = img_2.copy()\n",
    "\n",
    "    gray_image1 = cv2.cvtColor(image_1,cv2.COLOR_BGR2GRAY)\n",
    "    gray_image2 = cv2.cvtColor(image_2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    width1, height1 = image_1.shape[:2]\n",
    "    width2, height2 = image_2.shape[:2]\n",
    "\n",
    "    print(\"width = \", width1, \", height = \", height1)\n",
    "    print(\"width = \", width2, \", height = \", height2)\n",
    "\n",
    "    features_1,features_2 = [], []\n",
    "    corners_1, corners_2 = [],[]\n",
    "\n",
    "    print(\"all corner 1 len = \", len(all_corners_1))\n",
    "    print(\"all corner 2 len = \", len(all_corners_2))\n",
    "    \n",
    "    for corner in all_corners_1:\n",
    "        x,y = corner.ravel()\n",
    "        \n",
    "        if (x - (patch_size / 2) > 0) & (x + (patch_size / 2) < height1) & (y - (patch_size / 2) > 0) & (y + (patch_size / 2) < width1):\n",
    "            features_1.append(getFeatureDescriptor(gray_image1, y,x)) \n",
    "            corners_1.append([x,y])\n",
    "        else:\n",
    "            #print(\"ignored x, y\", x, y)\n",
    "            pass\n",
    "\n",
    "    for corner in all_corners_2:\n",
    "        x,y = corner.ravel()\n",
    "        if (x - (patch_size / 2) > 0) & (x + (patch_size / 2) < height2) & (y - (patch_size / 2) > 0) & (y + (patch_size / 2) < width2):\n",
    "            features_2.append(getFeatureDescriptor(gray_image2, y,x)) \n",
    "            corners_2.append([x,y]) \n",
    "\n",
    "    matched_pairs, match_level = [], []\n",
    "    for i, feat_1 in enumerate(features_1):\n",
    "        ssd = []  \n",
    "        for j, feat_2 in enumerate(features_2):\n",
    "            ssd.append(np.sum((feat_1 - feat_2)**2))\n",
    "        top_matche = np.argmin(ssd)\n",
    "        if ssd[top_matches[0]] / ssd[top_matches[1]] < alpha:   \n",
    "            matched_pairs.append([corners_1[i] , corners_2[top_matches[0]]])\n",
    "        matched_pairs.append([corners_1[i] , corners_2[top_matche]]) \n",
    "    print(\"matched pairs num = \", len(matched_pairs))\n",
    "    matched_pairs = np.array(matched_pairs)\n",
    "    return matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImageSizeSame(imgs):\n",
    "    images = imgs.copy()\n",
    "    sizes = []\n",
    "    for image in images:\n",
    "        x, y, ch = image.shape\n",
    "        sizes.append([x, y, ch])\n",
    "\n",
    "    sizes = np.array(sizes)\n",
    "    x_target, y_target, _ = np.max(sizes, axis = 0)\n",
    "    \n",
    "    images_resized = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image_resized = np.zeros((x_target, y_target, sizes[i, 2]), np.uint8)\n",
    "        image_resized[0:sizes[i, 0], 0:sizes[i, 1], 0:sizes[i, 2]] = image\n",
    "        images_resized.append(image_resized)\n",
    "\n",
    "    return images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMatches(img_1, img_2, matched_pairs, file_name):\n",
    "\n",
    "    image_1 = img_1.copy()\n",
    "    image_2 = img_2.copy()\n",
    "\n",
    "    image_1, image_2 = makeImageSizeSame([image_1, image_2])\n",
    "\n",
    "    concat = np.concatenate((image_1, image_2), axis = 1)\n",
    "    corners_1 = matched_pairs[:,0].copy()\n",
    "    corners_2  = matched_pairs[:,1].copy()\n",
    "    corners_2[:,0] += image_1.shape[1]\n",
    "\n",
    "    for (x1,y1) , (x2,y2) in zip(corners_1, corners_2):\n",
    "        cv2.line(concat, (x1,y1), (x2,y2), (0, 0, 255), 1)\n",
    "    \n",
    "      \n",
    "    cv2.imshow(file_name, concat)\n",
    "    cv2.waitKey() \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.imwrite(file_name, concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testShowMatches(image_1, image_2, partition_width = 20):\n",
    "    matched_pairs= []\n",
    "    I = np.linspace(10, 100, 10)\n",
    "    for i in I:\n",
    "        x1 = i\n",
    "        y1 = i\n",
    "        corner1 = np.int0(np.array([x1, y1]))\n",
    "\n",
    "        x2 = i\n",
    "        y2 = i\n",
    "        corner2 = np.int0(np.array([x2, y2]))\n",
    "        matched_pairs.append([corner1 , corner2])\n",
    "\n",
    "    matched_pairs = np.array(matched_pairs)\n",
    "    showMatches(image_1, image_2, matched_pairs, partition_width = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutliers(matched_pairs, outliers, accuracy, thresh):\n",
    "\n",
    "    set1 = matched_pairs[:, 0]\n",
    "    set2 = matched_pairs[:, 1]\n",
    "\n",
    "    N_best = 0\n",
    "    H_best = np.zeros([3, 3])\n",
    "    \n",
    "    e = outliers / set1.shape[0]\n",
    "    s = 4\n",
    "    p = accuracy\n",
    "    iterations = np.log(1 - p) / np.log(1 - np.power((1 - e), s))\n",
    "    iterations = np.int(iterations)\n",
    "    iterations = 4000\n",
    "\n",
    "    filtered_pair_indices = []\n",
    "\n",
    "    print(\"iterations = \", iterations)\n",
    "    for i in range(iterations):\n",
    "        #randomly select four points\n",
    "        n_rows = set1.shape[0]\n",
    "        random_indices = np.random.choice(n_rows, size=4)\n",
    "\n",
    "        set1_random = set1[random_indices]\n",
    "        set2_random = set2[random_indices]\n",
    "              \n",
    "        #compute homography\n",
    "        H = cv2.getPerspectiveTransform(np.float32(set1_random), np.float32(set2_random))\n",
    "\n",
    "        set1_dash = np.vstack((set1[:,0], set1[:,1], np.ones([1, n_rows])))\n",
    "        set1_transformed_dash = np.dot(H, set1_dash)\n",
    "        \n",
    "        t1 = set1_transformed_dash[0,:]/set1_transformed_dash[2,:]\n",
    "        t2 = set1_transformed_dash[1,:]/set1_transformed_dash[2,:]\n",
    "\n",
    "        set1_transformed = np.array([t1, t2]).T\n",
    "        #print(set1_transformed.shape)\n",
    "\n",
    "        E = calculateError(set2, set1_transformed)\n",
    "        \n",
    "     \n",
    "        E[E <= thresh] = 1\n",
    "        E[E > thresh] = 0\n",
    "    \n",
    "    \n",
    "        N = np.sum(E)\n",
    "\n",
    "\n",
    "        if N > N_best:\n",
    "            N_best = N\n",
    "            H_best = H\n",
    "            filtered_pair_indices = np.where(E == 1)\n",
    "    \n",
    "    filtered_set1 =  set1[filtered_pair_indices]\n",
    "    filtered_set2 =  set2[filtered_pair_indices]\n",
    "\n",
    "    print(\"Number of pairs after filtering = \", filtered_set1.shape[0])\n",
    "\n",
    "    filter_matched_pairs = np.zeros([filtered_set1.shape[0], filtered_set1.shape[1], 2])\n",
    "\n",
    "    filter_matched_pairs[:, 0, :] = filtered_set1\n",
    "    filter_matched_pairs[:, 1, :] = filtered_set2\n",
    "\n",
    "    filter_matched_pairs = filter_matched_pairs.astype(int)\n",
    "\n",
    "    H_inbuit, _ = cv2.findHomography(set1, set2)\n",
    "    print(\"inbuilt = \", H_inbuit)\n",
    "    print(\"Computed = \", H_best)\n",
    "\n",
    "    return H_best, filter_matched_pairs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateError(set1, set2):\n",
    "   \n",
    "    E = np.zeros(set1.shape[0])\n",
    "    tmp = set2 - set1\n",
    "    num = set1.shape[0]\n",
    "\n",
    "    for n in range(num):\n",
    "        E[n] = np.linalg.norm(tmp[n])\n",
    "    return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaptiveNonMaximalSuppression(imgs, C_maps, N_best):\n",
    "    \n",
    "    images = imgs.copy()\n",
    "    anms_img = []\n",
    "    anms_corners = []\n",
    "    for i,image in enumerate(images):\n",
    "\n",
    "        cmap = C_maps[i]\n",
    "        local_maximas = peak_local_max(cmap, min_distance=10)\n",
    "        n_strong = local_maximas.shape[0]\n",
    "        \n",
    "        r = [np.Infinity for i in range(n_strong)]\n",
    "        x=np.zeros((n_strong,1))\n",
    "        y=np.zeros((n_strong,1))\n",
    "        eu_dist = 0\n",
    "\n",
    "        for i in range(n_strong):\n",
    "            for j in range(n_strong):\n",
    "                x_j = local_maximas[j][0]\n",
    "                y_j = local_maximas[j][1]\n",
    "\n",
    "                x_i = local_maximas[i][0]\n",
    "                y_i = local_maximas[i][1]\n",
    "\n",
    "                if(cmap[x_j, y_j] > cmap[x_i, y_i]):\n",
    "                    eu_dist = np.square(x_j - x_i) + np.square(y_j - y_i)\n",
    "                if r[i] > eu_dist:\n",
    "                    r[i] = eu_dist\n",
    "                    x[i] = x_j\n",
    "                    y[i] = y_j\n",
    "\n",
    "        index = np.argsort(r)\n",
    "        index = np.flip(index)\n",
    "        index = index[0:N_best]\n",
    "        x_best=np.zeros((N_best,1))\n",
    "        y_best=np.zeros((N_best,1))\n",
    "\n",
    "        for i in range(N_best):\n",
    "            x_best[i] = np.int0(x[index[i]])\n",
    "            y_best[i] = np.int0(y[index[i]]) \n",
    "            cv2.circle(image, (y_best[i], x_best[i]), 3, (0, 255, 0), -1)\n",
    "\n",
    "        anms_corner = np.int0(np.concatenate((x_best, y_best), axis = 1))\n",
    "        anms_corners.append(anms_corner)\n",
    "        anms_img.append(image)\n",
    "    return anms_corners, anms_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitchImagePairs(img0, img1, H):\n",
    "\n",
    "    image0 = img0.copy()\n",
    "    image1 = img1.copy()\n",
    "\n",
    "    #stitch image 0 on image 1\n",
    "    print(\"shapes\")\n",
    "    print(image0.shape)\n",
    "    print(image1.shape)\n",
    "    \n",
    "\n",
    "    h0 ,w0 ,_ = image0.shape\n",
    "    h1 ,w1 ,_ = image1.shape\n",
    "\n",
    "    points_on_image0 = np.float32([[0, 0], [0, h0], [w0, h0], [w0, 0]]).reshape(-1,1,2)\n",
    "    points_on_image0_transformed = cv2.perspectiveTransform(points_on_image0, H)\n",
    "    print(\"transformed points = \", points_on_image0_transformed)\n",
    "    points_on_image1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1,1,2)\n",
    "\n",
    "    points_on_merged_images = np.concatenate((points_on_image0_transformed, points_on_image1), axis = 0)\n",
    "    points_on_merged_images_ = []\n",
    "\n",
    "    for p in range(len(points_on_merged_images)):\n",
    "        points_on_merged_images_.append(points_on_merged_images[p].ravel())\n",
    "\n",
    "    points_on_merged_images_ = np.array(points_on_merged_images_)\n",
    "\n",
    "    x_min, y_min = np.int0(np.min(points_on_merged_images_, axis = 0))\n",
    "    x_max, y_max = np.int0(np.max(points_on_merged_images_, axis = 0))\n",
    "\n",
    "    print(\"min, max\")\n",
    "    print(x_min, y_min)\n",
    "    print(x_max, y_max)\n",
    "\n",
    "    # overlap_area = cv2.polylines(image1,[np.int32(points_on_image0_transformed)],True,255,3, cv2.LINE_AA) \n",
    "    # cv2.imshow(\"original_image_overlapping.jpg\", overlap_area)\n",
    "    # cv2.waitKey() \n",
    "    # cv2.destroyAllWindows()\n",
    "    H_translate = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]]) # translate\n",
    "\n",
    "    image0_transformed_and_stitched = cv2.warpPerspective(image0, np.dot(H_translate, H), (x_max-x_min, y_max-y_min))\n",
    "    image0_transformed_and_stitched[-y_min:-y_min+h1, -x_min: -x_min+w1] = image1\n",
    "    return image0_transformed_and_stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformImage(image, H): \n",
    "\n",
    "    image0 = image.copy()\n",
    "    h0 ,w0 ,_ = image0.shape\n",
    "\n",
    "    points_on_image0 = np.float32([[0, 0], [0, h0], [w0, h0], [w0, 0]]).reshape(-1,1,2)\n",
    "    points_on_image0_transformed = cv2.perspectiveTransform(points_on_image0, H)\n",
    "\n",
    "    for p in range(len(points_on_image0_transformed)):\n",
    "        points_on_image0_transformed_.append(points_on_image0_transformed[p].ravel())\n",
    "\n",
    "    points_on_image0_transformed_ = np.array(points_on_image0_transformed_)\n",
    "\n",
    "    x_min, y_min = np.int0(np.min(points_on_image0_transformed, axis = 0))\n",
    "    x_max, y_max = np.int0(np.max(points_on_image0_transformed, axis = 0))\n",
    "    \n",
    "    H_translate = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]]) # translate\n",
    "\n",
    "    image0_transformed = cv2.warpPerspective(image0, np.dot(H_translate, H), (x_max-x_min, y_max-y_min))\n",
    "    image0_transformed[-y_min:-y_min+h1, -x_min: -x_min+w1] = image1\n",
    "    return image0_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImage(image):\n",
    "    \n",
    "    img = image.copy()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _,thresh = cv2.threshold(gray,5,255,cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    x,y,w,h = cv2.boundingRect(contours[len(contours)-1])\n",
    "    crop = img[y:y+h,x:x+w]\n",
    "\n",
    "    return crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinImages(img_array, choice, save_folder_name, n, show_steps = True):\n",
    "\n",
    "    image_array = img_array.copy()\n",
    "    N = len(image_array)\n",
    "    image0 = image_array[0]\n",
    "    for i in range(1, N):\n",
    "\n",
    "        print(\"processing image \", i)\n",
    "        image1 = image_array[i] \n",
    "\n",
    "        image_pair = [image0, image1]\n",
    "        \n",
    "        detected_corners, cmaps, corner_images = detectCorners(image_pair, choice)\n",
    "        if show_steps:\n",
    "            displayImages(corner_images, save_folder_name + \"/corners\" + str(n) + \".png\")\n",
    "        \"\"\"\n",
    "        Perform ANMS: Adaptive Non-Maximal Suppression\n",
    "        Save ANMS output as anms.png\n",
    "        \"\"\"\n",
    "        if (choice == 1):\n",
    "            print(\"Applying ALMS.\")\n",
    "            detected_corners, anms_image = AdaptiveNonMaximalSuppression(image_pair, cmaps, 500)\n",
    "            if show_steps:\n",
    "                displayImages(anms_image, save_folder_name + \"/anms_output\" + str(n) + \".png\")\n",
    "        else:\n",
    "            print(\"goodFeaturesToTrack is already using ALMS.\") #review\n",
    "\n",
    "        detected_corners0 = detected_corners[0]\n",
    "        detected_corners1 = detected_corners[1]\n",
    "                \n",
    "        matched_pairs = getPairs(image0, image1, detected_corners0, detected_corners1, patch_size = 40, alpha = 0.9 )\n",
    "        if show_steps:\n",
    "            showMatches(image0, image1, matched_pairs, save_folder_name + \"/matched_pairs\" + str(n) + \".png\")\n",
    "        \"\"\"\n",
    "        Refine: RANSAC, Estimate Homography\n",
    "        \"\"\"\n",
    "        H,filtered_matched_pairs = filterOutliers(matched_pairs, 20, 0.9, 5)\n",
    "        if show_steps:\n",
    "            showMatches(image0, image1, filtered_matched_pairs, save_folder_name + \"/filtered_matched_pairs\" + str(n) + \".png\")\n",
    "        \"\"\"\n",
    "        Image Warping + Blending\n",
    "        Save Panorama output as mypano.png\n",
    "        \"\"\"\n",
    "        stitched_image = stitchImagePairs(image0, image1, H)\n",
    "        stitched_image = cropImage(stitched_image)\n",
    "        if show_steps:\n",
    "            cv2.imshow(save_folder_name + \"/pano\" + str(n) + \".png\", stitched_image)\n",
    "            cv2.waitKey() \n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        cv2.imwrite(save_folder_name + \"/pano\" + str(n) + \".png\", stitched_image)\n",
    "        image0 = stitched_image\n",
    "\n",
    "    return image0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoPano():\n",
    "\n",
    "    # Parser = argparse.ArgumentParser()\n",
    "    # Parser.add_argument('--BasePath', default='/home/sakshi/courses/CMSC733/sakshi_p1/Phase1/', help='base path')\n",
    "    # Parser.add_argument('--ImagesFolder', default='Data/Train/Set1', help='folder for images')\n",
    "    # Parser.add_argument('--SaveFolderName', default='Code/Results/Set1', help='Folder to save results')\n",
    "    # Parser.add_argument('--ShowImages', type = bool, default= True, help='show images or not')\n",
    "    # Args = Parser.parse_args()\n",
    "    BasePath = '/home/sakshi/courses/CMSC733/sakshi_p1/Phase1/'\n",
    "    ImagesFolder = 'Data/Test/TestSet4'\n",
    "    SaveFolderName = 'Code/Results/TestSet4'\n",
    "    ShowImages = True\n",
    "\n",
    "    use_harris = False\n",
    "\n",
    "    images = readImageSet(BasePath + ImagesFolder)\n",
    "    if ShowImages:\n",
    "        displayImages(images, BasePath + ImagesFolder + \"/input.png\")\n",
    "\n",
    "    N_images = len(images)\n",
    "\n",
    "    choice = 2\n",
    "    if use_harris:\n",
    "        choice = 1\n",
    "\n",
    "    N_first_half = round(N_images/2)\n",
    "    N_second_half = N_images - N_first_half\n",
    "    print(N_first_half, \" and \", N_second_half)\n",
    "\n",
    "    N_first_half_images = []\n",
    "    N_second_half_images = []\n",
    "\n",
    "    while N_images is not 2:\n",
    "        print(\"N = \", N_images, \" N_half = \", N_first_half)\n",
    "        merged_images = []\n",
    "        for n in range(0, N_first_half, 2):\n",
    "            if (n+1) <= N_first_half:\n",
    "                img_array = images[n:n+2]\n",
    "                print(\"combining: \", n, n+1)\n",
    "                I = joinImagesTest(img_array, choice, BasePath + SaveFolderName, n, ShowImages)\n",
    "                merged_images.append(I)\n",
    "            else:\n",
    "                print(\"adding: \", n)\n",
    "                merged_images.append(images[n])\n",
    "\n",
    "        for n in range(N_first_half, N_images, 2):\n",
    "            if (n+1) < N_images:\n",
    "                img_array = images[n:n+2]\n",
    "                img_array.reverse()\n",
    "                print(\"combining: \", n+1, n)\n",
    "                I = joinImagesTest(img_array, choice, BasePath + SaveFolderName, n, ShowImages)\n",
    "                merged_images.append(I)\n",
    "            else:\n",
    "                print(\"adding: \", n, n)\n",
    "                merged_images.append(images[n])\n",
    "    \n",
    "        images = merged_images\n",
    "        N_images = len(images)\n",
    "        N_first_half = round(N_images/2)\n",
    "        N_second_half = N_images - N_first_half\n",
    "\n",
    "    print(\"final merging\")\n",
    "    \n",
    "    final = joinImages(merged_images, choice, BasePath + SaveFolderName, 100, ShowImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading images from  /home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Test/TestSet4\n",
      "Found  ['1.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg']\n",
      "2  and  3\n",
      "N =  5  N_half =  2\n",
      "combining:  0 1\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  1280 , height =  720\n",
      "width =  1280 , height =  720\n",
      "all corner 1 len =  840\n",
      "all corner 2 len =  1000\n",
      "matched pairs num =  735\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  419\n",
      "inbuilt =  [[ 1.11664529e+00 -1.68849734e-01 -1.27425600e+01]\n",
      " [ 1.53870342e+00  7.24606834e-01 -1.07743686e+03]\n",
      " [ 1.55526845e-03 -1.04189769e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.18315372e+00  1.02255879e-02 -3.29876612e+02]\n",
      " [ 1.76009871e-01  1.11827380e+00 -5.26916744e+01]\n",
      " [ 2.71285227e-04 -9.58801623e-06  1.00000000e+00]]\n",
      "H matrix is:  [[ 1.18315372e+00  1.02255879e-02 -3.29876612e+02]\n",
      " [ 1.76009871e-01  1.11827380e+00 -5.26916744e+01]\n",
      " [ 2.71285227e-04 -9.58801623e-06  1.00000000e+00]]\n",
      "shapes\n",
      "(1280, 720, 3)\n",
      "(1280, 720, 3)\n",
      "transformed points =  [[[-329.87662   -52.691673]]\n",
      "\n",
      " [[-320.724    1395.8293  ]]\n",
      "\n",
      " [[ 452.28992  1272.4927  ]]\n",
      "\n",
      " [[ 436.69623    61.937473]]]\n",
      "min x.y =  -329 -52\n",
      "max x,y =  720 1395\n",
      "h1 =  1280 w1 =  720\n",
      "SIZEEEEEEE =  (1447, 1049, 3)\n",
      "combining:  3 2\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  1280 , height =  720\n",
      "width =  1280 , height =  720\n",
      "all corner 1 len =  577\n",
      "all corner 2 len =  950\n",
      "matched pairs num =  525\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  39\n",
      "inbuilt =  [[-2.37621231e+00 -1.02232948e+00  1.48747151e+03]\n",
      " [-9.47523303e+00 -4.07196419e+00  5.92697795e+03]\n",
      " [-1.60360679e-03 -6.85662892e-04  1.00000000e+00]]\n",
      "Computed =  [[-5.77925687e-01  1.32436443e-01  1.15077680e+02]\n",
      " [-5.40744858e+00  1.23876457e+00  1.07708839e+03]\n",
      " [-5.02616486e-03  1.15295384e-03  1.00000000e+00]]\n",
      "Cannot match image\n",
      "H matrix is:  [[-5.77925687e-01  1.32436443e-01  1.15077680e+02]\n",
      " [-5.40744858e+00  1.23876457e+00  1.07708839e+03]\n",
      " [-5.02616486e-03  1.15295384e-03  1.00000000e+00]]\n",
      "adding:  4 4\n",
      "N =  3  N_half =  2\n",
      "combining:  0 1\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  1447 , height =  1049\n",
      "width =  1280 , height =  720\n",
      "all corner 1 len =  1000\n",
      "all corner 2 len =  577\n",
      "matched pairs num =  979\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  56\n",
      "inbuilt =  [[ 2.17941361e+02 -1.50750782e+02 -1.46475954e+04]\n",
      " [-6.70615730e+02  4.65677686e+02  4.38939231e+04]\n",
      " [-2.53754607e-02  1.86486196e-02  1.00000000e+00]]\n",
      "Computed =  [[ 7.33647575e-01 -1.54703945e+00  2.47000000e+02]\n",
      " [ 2.28707949e+00 -4.82275457e+00  7.70000000e+02]\n",
      " [ 2.97023310e-03 -6.26331762e-03  1.00000000e+00]]\n",
      "Cannot match image\n",
      "H matrix is:  [[ 7.33647575e-01 -1.54703945e+00  2.47000000e+02]\n",
      " [ 2.28707949e+00 -4.82275457e+00  7.70000000e+02]\n",
      " [ 2.97023310e-03 -6.26331762e-03  1.00000000e+00]]\n",
      "adding:  2 2\n",
      "final merging\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  1447 , height =  1049\n",
      "width =  1280 , height =  720\n",
      "all corner 1 len =  1000\n",
      "all corner 2 len =  838\n",
      "matched pairs num =  979\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  34\n",
      "inbuilt =  [[ 1.27984088e+00 -2.02735206e-01 -6.47176755e+02]\n",
      " [-1.89680891e+00  2.99370277e-01  9.58927633e+02]\n",
      " [-1.97966312e-03  3.12857483e-04  1.00000000e+00]]\n",
      "Computed =  [[-2.52715632e-01  1.19343932e-01  3.30000000e+01]\n",
      " [-4.47995893e+00  2.11564243e+00  5.85000000e+02]\n",
      " [-7.65804945e-03  3.61648279e-03  1.00000000e+00]]\n",
      "shapes\n",
      "(1447, 1049, 3)\n",
      "(1280, 720, 3)\n",
      "transformed points =  [[[ 33. 585.]]\n",
      "\n",
      " [[ 33. 585.]]\n",
      "\n",
      " [[ 33. 585.]]\n",
      "\n",
      " [[ 33. 585.]]]\n",
      "min, max\n",
      "0 0\n",
      "720 1280\n"
     ]
    }
   ],
   "source": [
    "autoPano()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading images from  /home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Test/TestSet4\n",
      "Found  ['1.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg']\n",
      "2  and  3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Parser = argparse.ArgumentParser()\n",
    "# Parser.add_argument('--BasePath', default='/home/sakshi/courses/CMSC733/sakshi_p1/Phase1/', help='base path')\n",
    "# Parser.add_argument('--ImagesFolder', default='Data/Train/Set1', help='folder for images')\n",
    "# Parser.add_argument('--SaveFolderName', default='Code/Results/Set1', help='Folder to save results')\n",
    "# Parser.add_argument('--ShowImages', type = bool, default= True, help='show images or not')\n",
    "# Args = Parser.parse_args()\n",
    "BasePath = '/home/sakshi/courses/CMSC733/sakshi_p1/Phase1/'\n",
    "ImagesFolder = 'Data/Test/TestSet4'\n",
    "SaveFolderName = 'Code/Results/TestSet4'\n",
    "ShowImages = True\n",
    "\n",
    "use_harris = False\n",
    "\n",
    "images = readImageSet(BasePath + ImagesFolder)\n",
    "if ShowImages:\n",
    "    displayImages(images, BasePath + ImagesFolder + \"/input.png\")\n",
    "\n",
    "N_images = len(images)\n",
    "\n",
    "choice = 2\n",
    "if use_harris:\n",
    "    choice = 1\n",
    "\n",
    "N_first_half = round(N_images/2)\n",
    "N_second_half = N_images - N_first_half\n",
    "print(N_first_half, \" and \", N_second_half)\n",
    "\n",
    "N_first_half_images = []\n",
    "N_second_half_images = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  1280 , height =  720\n",
      "width =  1280 , height =  720\n",
      "all corner 1 len =  840\n",
      "all corner 2 len =  1000\n",
      "matched pairs num =  735\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  417\n",
      "inbuilt =  [[ 1.11664529e+00 -1.68849734e-01 -1.27425600e+01]\n",
      " [ 1.53870342e+00  7.24606834e-01 -1.07743686e+03]\n",
      " [ 1.55526845e-03 -1.04189769e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.13541288e+00  8.04157861e-04 -3.08622403e+02]\n",
      " [ 1.60299578e-01  1.04864193e+00 -2.79047453e+01]\n",
      " [ 2.48030977e-04 -4.59507568e-05  1.00000000e+00]]\n",
      "H matrix is:  [[ 1.13541288e+00  8.04157861e-04 -3.08622403e+02]\n",
      " [ 1.60299578e-01  1.04864193e+00 -2.79047453e+01]\n",
      " [ 2.48030977e-04 -4.59507568e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(1280, 720, 3)\n",
      "(1280, 720, 3)\n",
      "transformed points =  [[[-308.6224    -27.904745]]\n",
      "\n",
      " [[-326.81537  1396.4945  ]]\n",
      "\n",
      " [[ 455.367    1276.8502  ]]\n",
      "\n",
      " [[ 431.76865    74.25103 ]]]\n",
      "min x.y =  -326 -27\n",
      "max x,y =  720 1396\n",
      "h1 =  1280 w1 =  720\n",
      "SIZEEEEEEE =  (1423, 1046, 3)\n"
     ]
    }
   ],
   "source": [
    "img_array1 = [images[0], images[1]] \n",
    "I1 = joinImagesTest(img_array1, choice, BasePath + SaveFolderName, 1, ShowImages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  1280 , height =  720\n",
      "width =  1280 , height =  720\n",
      "all corner 1 len =  950\n",
      "all corner 2 len =  577\n",
      "matched pairs num =  815\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  37\n",
      "inbuilt =  [[-4.69883505e-01  5.20023413e-01 -3.23559129e+02]\n",
      " [ 2.08822245e+00 -2.25501959e+00  1.37556577e+03]\n",
      " [ 1.54597284e-03 -1.65302212e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.58558737e-01 -6.57284667e-01  2.58201926e+02]\n",
      " [ 4.78583998e-01 -1.96426717e+00  7.69763036e+02]\n",
      " [ 6.15230961e-04 -2.54690211e-03  1.00000000e+00]]\n",
      "Cannot match image\n",
      "H matrix is:  [[ 1.58558737e-01 -6.57284667e-01  2.58201926e+02]\n",
      " [ 4.78583998e-01 -1.96426717e+00  7.69763036e+02]\n",
      " [ 6.15230961e-04 -2.54690211e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "img_array2 = [images[2], images[3]] \n",
    "I2 = joinImagesTest(img_array2, choice, BasePath + SaveFolderName, 1, ShowImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"h\", I2)\n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "detecting corners ...\nusing Shi-Tomashi corner detection method.\nusing Shi-Tomashi corner detection method.\n"
     ]
    }
   ],
   "source": [
    "detected_corners, cmaps, corner_images = detectCorners(img_array2, choice)\n",
    "if show_steps:\n",
    "    displayImages(corner_images, save_folder_name + \"/corners\" + str(n) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "width =  1280 , height =  720\n",
      "width =  1280 , height =  720\n",
      "all corner 1 len =  950\n",
      "all corner 2 len =  577\n",
      "matched pairs num =  815\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  35\n",
      "inbuilt =  [[-4.69883505e-01  5.20023413e-01 -3.23559129e+02]\n",
      " [ 2.08822245e+00 -2.25501959e+00  1.37556577e+03]\n",
      " [ 1.54597284e-03 -1.65302212e-03  1.00000000e+00]]\n",
      "Computed =  [[-4.64727721e-01 -4.53878352e-02  2.57825681e+02]\n",
      " [-1.38936753e+00 -1.36599605e-01  7.71654135e+02]\n",
      " [-1.79402473e-03 -1.79292332e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "detected_corners0 = detected_corners[0]\n",
    "detected_corners1 = detected_corners[1]\n",
    "        \n",
    "matched_pairs = getPairs(image0, image1, detected_corners0, detected_corners1, patch_size = 40, alpha = 0.9 )\n",
    "if show_steps:\n",
    "    showMatches(image0, image1, matched_pairs, save_folder_name + \"/matched_pairs\" + str(n) + \".png\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Refine: RANSAC, Estimate Homography\n",
    "\"\"\"\n",
    "H,filtered_matched_pairs = filterOutliers(matched_pairs, 20, 0.9, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cannot match image\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(filtered_matched_pairs[:,1,:], return_counts=True, axis = 0)\n",
    "unique_count = unique.shape[0]\n",
    "max_count = np.max(counts)\n",
    "if(unique_count < 10 and max_count > 8):\n",
    "    print(\"Cannot match image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  758 , height =  568\n",
      "width =  758 , height =  568\n",
      "all corner 1 len =  1000\n",
      "all corner 2 len =  860\n",
      "matched pairs num =  927\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  204\n",
      "inbuilt =  [[ 7.79165636e-01 -7.99255581e-01  1.71679301e+02]\n",
      " [ 2.51460020e-01 -2.47461313e-01  4.84423216e+01]\n",
      " [ 4.38525202e-03 -4.56923847e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.35816735e+00 -2.34412049e-01 -3.82199202e+02]\n",
      " [ 6.38612987e-01  1.19911801e+00 -2.15666547e+02]\n",
      " [ 9.47435977e-04 -2.15751764e-04  1.00000000e+00]]\n",
      "shapes\n",
      "(758, 568, 3)\n",
      "(758, 568, 3)\n",
      "transformed points =  [[[-382.1992  -215.66655]]\n",
      "\n",
      " [[-669.3487   828.80804]]\n",
      "\n",
      " [[ 153.90291  768.21924]]\n",
      "\n",
      " [[ 253.0582    95.61242]]]\n",
      "min, max\n",
      "-669 -215\n",
      "568 828\n"
     ]
    }
   ],
   "source": [
    "img_array2 = [images[1], images[2]] \n",
    "I2 = joinImages(img_array2, choice, BasePath + SaveFolderName, 1, ShowImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "u =np.where(I2 == [0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  10,   10,   10, ..., 1052, 1052, 1052])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "u[0] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'I2' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3445ed4babf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_array3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mI3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoinImagesTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasePath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSaveFolderName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mShowImages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I2' is not defined"
     ]
    }
   ],
   "source": [
    "img_array3 = [I1, I2] \n",
    "I3 = joinImagesTest(img_array3, choice, BasePath + SaveFolderName, 1, ShowImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitchImagePairsTest(img0, img1, H):\n",
    "\n",
    "    image0 = img0.copy()\n",
    "    image1 = img1.copy()\n",
    "\n",
    "    #stitch image 0 on image 1\n",
    "    print(\"shapes\")\n",
    "    print(image0.shape)\n",
    "    print(image1.shape)\n",
    "    \n",
    "\n",
    "    h0 ,w0 ,_ = image0.shape\n",
    "    h1 ,w1 ,_ = image1.shape\n",
    "\n",
    "    points_on_image0 = np.float32([[0, 0], [0, h0], [w0, h0], [w0, 0]]).reshape(-1,1,2)\n",
    "    points_on_image0_transformed = cv2.perspectiveTransform(points_on_image0, H)\n",
    "    print(\"transformed points = \", points_on_image0_transformed)\n",
    "    points_on_image1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1,1,2)\n",
    "\n",
    "    points_on_merged_images = np.concatenate((points_on_image0_transformed, points_on_image1), axis = 0)\n",
    "    points_on_merged_images_ = []\n",
    "\n",
    "    for p in range(len(points_on_merged_images)):\n",
    "        points_on_merged_images_.append(points_on_merged_images[p].ravel())\n",
    "\n",
    "    points_on_merged_images_ = np.array(points_on_merged_images_)\n",
    "\n",
    "    x_min, y_min = np.int0(np.min(points_on_merged_images_, axis = 0))\n",
    "    x_max, y_max = np.int0(np.max(points_on_merged_images_, axis = 0))\n",
    "\n",
    "   \n",
    "    print(\"min x.y = \", x_min, y_min)\n",
    "    print(\"max x,y = \", x_max, y_max)\n",
    "\n",
    "    # overlap_area = cv2.polylines(image1,[np.int32(points_on_image0_transformed)],True,255,3, cv2.LINE_AA) \n",
    "    # cv2.imshow(\"original_image_overlapping.jpg\", overlap_area)\n",
    "    # cv2.waitKey() \n",
    "    # cv2.destroyAllWindows()\n",
    "    H_translate = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]]) # translate\n",
    "\n",
    "    image0_transformed_and_stitched = cv2.warpPerspective(image0, np.dot(H_translate, H), (x_max-x_min, y_max-y_min))\n",
    "    print(\"h1 = \", h1, \"w1 = \", w1)\n",
    "\n",
    "    # images_stitched = image0_transformed_and_stitched.copy()\n",
    "    image0_transformed_and_stitched[-y_min:-y_min+h1, -x_min:-x_min+w1] = image1\n",
    "\n",
    "    # indices = np.where(image1 == [0,0,0])\n",
    "    # y = indices[0] + -y_min \n",
    "    # x = indices[1] + -x_min \n",
    "\n",
    "    # images_stitched[y,x] = image0_transformed_and_stitched[y,x]\n",
    "                \n",
    "    return image0_transformed_and_stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinImagesTest(img_array, choice, save_folder_name, n, show_steps = True):\n",
    "\n",
    "    image_array = img_array.copy()\n",
    "    N = len(image_array)\n",
    "    image0 = image_array[0]\n",
    "    for i in range(1, N):\n",
    "\n",
    "        print(\"processing image \", i)\n",
    "        image1 = image_array[i] \n",
    "\n",
    "        image_pair = [image0, image1]\n",
    "        \n",
    "        detected_corners, cmaps, corner_images = detectCorners(image_pair, choice)\n",
    "        if show_steps:\n",
    "            displayImages(corner_images, save_folder_name + \"/corners\" + str(n) + \".png\")\n",
    "        \"\"\"\n",
    "        Perform ANMS: Adaptive Non-Maximal Suppression\n",
    "        Save ANMS output as anms.png\n",
    "        \"\"\"\n",
    "        if (choice == 1):\n",
    "            print(\"Applying ALMS.\")\n",
    "            detected_corners, anms_image = AdaptiveNonMaximalSuppression(image_pair, cmaps, 500)\n",
    "            if show_steps:\n",
    "                displayImages(anms_image, save_folder_name + \"/anms_output\" + str(n) + \".png\")\n",
    "        else:\n",
    "            print(\"goodFeaturesToTrack is already using ALMS.\") #review\n",
    "\n",
    "        detected_corners0 = detected_corners[0]\n",
    "        detected_corners1 = detected_corners[1]\n",
    "                \n",
    "        matched_pairs = getPairs(image0, image1, detected_corners0, detected_corners1, patch_size = 40, alpha = 0.9 )\n",
    "        if show_steps:\n",
    "            showMatches(image0, image1, matched_pairs, save_folder_name + \"/matched_pairs\" + str(n) + \".png\")\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Refine: RANSAC, Estimate Homography\n",
    "        \"\"\"\n",
    "        H,filtered_matched_pairs = filterOutliers(matched_pairs, 20, 0.9, 15)\n",
    "\n",
    "        #remove the points that converge to a single point\n",
    "\n",
    "        if show_steps:\n",
    "            showMatches(image0, image1, filtered_matched_pairs, save_folder_name + \"/filtered_matched_pairs\" + str(n) + \".png\")\n",
    "\n",
    "        unique, counts = np.unique(filtered_matched_pairs[:,1,:], return_counts=True, axis = 0)\n",
    "        unique_count = unique.shape[0]\n",
    "        max_count = np.max(counts)\n",
    "        stitching = True\n",
    "        if(unique_count < 10 and max_count > 8):\n",
    "            print(\"Cannot match image\")\n",
    "            stitching = False\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Image Warping + Blending\n",
    "        Save Panorama output as mypano.png\n",
    "        \"\"\"\n",
    "        print(\"H matrix is: \", H)\n",
    "        if(stitching):\n",
    "            stitched_image = stitchImagePairsTest(image0, image1, H)\n",
    "            print(\"SIZEEEEEEE = \",stitched_image.shape )\n",
    "            stitched_image = cropImage(stitched_image)\n",
    "            if show_steps:\n",
    "                cv2.imshow(save_folder_name + \"/pano\" + str(n) + \".png\", stitched_image)\n",
    "                cv2.waitKey() \n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "            cv2.imwrite(save_folder_name + \"/pano\" + str(n) + \".png\", stitched_image)\n",
    "            image0 = stitched_image\n",
    "\n",
    "    return image0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading images from  /home/sakshi/courses/CMSC733/sakshi_p1/Phase1/Data/Train/Set3\n",
      "Found  ['1.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg']\n",
      "4  and  4\n",
      "N =  8  N_half =  4\n",
      "combining:  0 1\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  807 , height =  605\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  489\n",
      "all corner 2 len =  561\n",
      "matched pairs num =  442\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  109\n",
      "inbuilt =  [[ 8.98932359e-01 -8.09269316e-01  2.35080040e+02]\n",
      " [ 1.94672202e+00 -1.72142241e+00  4.96172856e+02]\n",
      " [ 3.89482378e-03 -3.46407303e-03  1.00000000e+00]]\n",
      "Computed =  [[ 1.42847686e+00 -7.05199963e-02 -3.86733963e+02]\n",
      " [ 2.96495746e-01  1.48522195e+00 -1.62315629e+02]\n",
      " [ 8.58048285e-04  6.42618054e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(807, 605, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[-386.73398  -162.31563 ]]\n",
      "\n",
      " [[-421.77087   985.16833 ]]\n",
      "\n",
      " [[ 267.72162   773.8097  ]]\n",
      "\n",
      " [[ 314.32327    11.233021]]]\n",
      "min, max\n",
      "-421 -162\n",
      "605 985\n",
      "combining:  2 3\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  807 , height =  605\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  429\n",
      "all corner 2 len =  422\n",
      "matched pairs num =  386\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  187\n",
      "inbuilt =  [[-7.28248872e+00 -3.45472708e-01  8.90699601e+02]\n",
      " [-1.76804179e+01 -1.22585004e+00  2.44685023e+03]\n",
      " [-9.89539929e-03 -1.22353055e-04  1.00000000e+00]]\n",
      "Computed =  [[ 1.23026151e+00  3.81715157e-02 -2.46401773e+02]\n",
      " [ 1.11160095e-01  1.16731431e+00 -3.59897565e+01]\n",
      " [ 4.29423454e-04  8.83374777e-06  1.00000000e+00]]\n",
      "shapes\n",
      "(807, 605, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[-246.40178   -35.989758]]\n",
      "\n",
      " [[-214.07127   899.6196  ]]\n",
      "\n",
      " [[ 417.31653   768.22296 ]]\n",
      "\n",
      " [[ 395.2262     24.815107]]]\n",
      "min, max\n",
      "-246 -35\n",
      "605 899\n",
      "combining:  5 4\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  807 , height =  605\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  360\n",
      "all corner 2 len =  435\n",
      "matched pairs num =  335\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  130\n",
      "inbuilt =  [[-1.06160707e+03  8.11626687e+02  6.08756345e+03]\n",
      " [-1.60875462e+03  1.23145835e+03  8.14117585e+03]\n",
      " [-3.52523345e+00  2.71748615e+00  1.00000000e+00]]\n",
      "Computed =  [[ 6.86916246e-01 -2.70752696e-02  2.17153639e+02]\n",
      " [-1.75955034e-01  8.68517643e-01  5.09445112e+01]\n",
      " [-4.55210049e-04 -3.05714200e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(807, 605, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[217.15364  50.94451]]\n",
      "\n",
      " [[200.24414 770.85614]]\n",
      "\n",
      " [[872.78876 922.0757 ]]\n",
      "\n",
      " [[873.2263  -76.60564]]]\n",
      "min, max\n",
      "0 -76\n",
      "873 922\n",
      "combining:  7 6\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  807 , height =  605\n",
      "width =  807 , height =  605\n",
      "all corner 1 len =  338\n",
      "all corner 2 len =  371\n",
      "matched pairs num =  303\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  212\n",
      "inbuilt =  [[-5.64704695e-01 -1.41582635e-01  3.61545004e+02]\n",
      " [-9.46315307e-01 -1.57742839e-01  5.46116206e+02]\n",
      " [-1.62438234e-03 -3.54812627e-04  1.00000000e+00]]\n",
      "Computed =  [[ 8.95312063e-01  3.68570875e-02  1.30030012e+02]\n",
      " [-8.91952153e-02  1.01257434e+00  1.83363169e+00]\n",
      " [-2.65790097e-04  7.13570084e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(807, 605, 3)\n",
      "(807, 605, 3)\n",
      "transformed points =  [[[130.03001     1.8336316]]\n",
      "\n",
      " [[151.07407   774.38794  ]]\n",
      "\n",
      " [[782.1716    853.0701   ]]\n",
      "\n",
      " [[800.40063   -62.11828  ]]]\n",
      "min, max\n",
      "0 -62\n",
      "800 853\n",
      "N =  4  N_half =  2\n",
      "combining:  0 1\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  1147 , height =  1026\n",
      "width =  934 , height =  851\n",
      "all corner 1 len =  790\n",
      "all corner 2 len =  587\n",
      "matched pairs num =  767\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  21\n",
      "inbuilt =  [[ 4.91522329e-01 -9.74343091e-01  4.16947333e+02]\n",
      " [ 6.15337268e-01 -1.21675558e+00  5.19635350e+02]\n",
      " [ 1.18085919e-03 -2.33848407e-03  1.00000000e+00]]\n",
      "Computed =  [[-5.00613719e-02  3.54224122e-02  1.40672521e+01]\n",
      " [-1.17928809e+00  7.56541710e-02  8.73539709e+02]\n",
      " [-1.38050253e-03  1.20738983e-04  1.00000000e+00]]\n",
      "shapes\n",
      "(1147, 1026, 3)\n",
      "(934, 851, 3)\n",
      "transformed points =  [[[ 14.067252 873.53973 ]]\n",
      "\n",
      " [[ 48.04335  843.5007  ]]\n",
      "\n",
      " [[-11.996026 898.2633  ]]\n",
      "\n",
      " [[ 89.567986 807.9093  ]]]\n",
      "min, max\n",
      "-11 0\n",
      "851 934\n",
      "combining:  3 2\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  915 , height =  800\n",
      "width =  998 , height =  873\n",
      "all corner 1 len =  433\n",
      "all corner 2 len =  603\n",
      "matched pairs num =  405\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  103\n",
      "inbuilt =  [[ 1.96242107e-01 -7.11327010e-01  4.23562967e+02]\n",
      " [ 5.29434866e-02 -1.89523534e-01  1.12561100e+02]\n",
      " [ 4.63962800e-04 -1.68006394e-03  1.00000000e+00]]\n",
      "Computed =  [[ 6.49831776e-01 -6.95431163e-02  3.32730152e+02]\n",
      " [-2.68129657e-01  8.54404276e-01  6.29053283e+01]\n",
      " [-6.02411307e-04 -7.91599283e-05  1.00000000e+00]]\n",
      "shapes\n",
      "(915, 800, 3)\n",
      "(998, 873, 3)\n",
      "transformed points =  [[[ 332.73016    62.905327]]\n",
      "\n",
      " [[ 290.11136   910.6444  ]]\n",
      "\n",
      " [[1770.4072   1414.1057  ]]\n",
      "\n",
      " [[1645.7119   -292.6209  ]]]\n",
      "min, max\n",
      "0 -292\n",
      "1770 1414\n",
      "final merging\n",
      "processing image  1\n",
      "detecting corners ...\n",
      "using Shi-Tomashi corner detection method.\n",
      "using Shi-Tomashi corner detection method.\n",
      "goodFeaturesToTrack is already using ALMS.\n",
      "width =  934 , height =  862\n",
      "width =  1683 , height =  1706\n",
      "all corner 1 len =  590\n",
      "all corner 2 len =  824\n",
      "matched pairs num =  566\n",
      "iterations =  4000\n",
      "Number of pairs after filtering =  204\n",
      "inbuilt =  [[-2.03640481e+00 -4.42163838e-01  8.51813550e+02]\n",
      " [-2.63929040e+00 -5.25115116e-01  1.06646127e+03]\n",
      " [-2.47900800e-03 -4.89280380e-04  1.00000000e+00]]\n",
      "Computed =  [[ 1.54382790e+00  2.44743912e-02 -7.29021524e+02]\n",
      " [ 4.64914575e-01  1.39992645e+00  1.86887884e+02]\n",
      " [ 6.36705823e-04 -9.78652008e-06  1.00000000e+00]]\n",
      "shapes\n",
      "(934, 862, 3)\n",
      "(1683, 1706, 3)\n",
      "transformed points =  [[[-729.02155  186.88788]]\n",
      "\n",
      " [[-712.67676 1508.2051 ]]\n",
      "\n",
      " [[ 405.67465 1230.8734 ]]\n",
      "\n",
      " [[ 388.5217   379.40915]]]\n",
      "min, max\n",
      "-729 0\n",
      "1706 1683\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    autoPano()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}