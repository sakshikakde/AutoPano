{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NhH6B3g6wQ1Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from skimage import data, exposure, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "from Misc.MiscUtils import *\n",
    "from Misc.DataUtils import *\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import string\n",
    "from termcolor import colored, cprint\n",
    "import math as m\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Don't generate pyc codes\n",
    "\n",
    "from Network.Network import homographyNet,unsupervised_HomographyNet\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lg3JfWINwQ1j"
   },
   "outputs": [],
   "source": [
    "def loadData(folder_name, files_in_dir, points_list, batch_size, shuffle = True):\n",
    "\n",
    "    patch_pairs = []\n",
    "    corners1 = []\n",
    "    patches2 = []\n",
    "    images1 = []\n",
    "\n",
    "\n",
    "    if(len(files_in_dir) < batch_size):\n",
    "        print(\"The data has only \", len(files_in_dir) , \" images and you are trying to get \",batch_size, \" images\")\n",
    "        return 0\n",
    "\n",
    "    for n in range(batch_size):\n",
    "        index = random.randint(0, len(files_in_dir)-1)  #len(files_in_dir)-1\n",
    "       \n",
    "        patch1_name = folder_name + os.sep + \"PA/\" + files_in_dir[index, 0]\n",
    "        patch1 = cv2.imread(patch1_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        patch2_name = folder_name + os.sep + \"PB/\" + files_in_dir[index, 0] \n",
    "        patch2 = cv2.imread(patch2_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        image1_name = folder_name + os.sep + \"IA/\" + files_in_dir[index, 0]\n",
    "        image1 = cv2.imread(image1_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if(patch1 is None) or (patch2 is None):\n",
    "            print(patch1_name, \" is empty. Ignoring ...\")\n",
    "            continue\n",
    "\n",
    "        patch1 = np.float32(patch1)\n",
    "        patch2 = np.float32(patch2) \n",
    "        image1 = np.float32(image1)   \n",
    "\n",
    "        #combine images along depth\n",
    "        patch_pair = np.dstack((patch1, patch2))     \n",
    "        corner1 = points_list[index, :, :, 0]\n",
    "        \n",
    "        \n",
    "        patch_pairs.append(patch_pair)\n",
    "        corners1.append(corner1)\n",
    "        patches2.append(patch2.reshape(128, 128, 1))\n",
    "\n",
    "        images1.append(image1.reshape(image1.shape[0], image1.shape[1], 1))\n",
    "\n",
    "\n",
    "    return np.array(patch_pairs), np.array(corners1), np.array(patches2), np.array(images1)\n",
    "\n",
    "\n",
    "def TrainModel(PatchPairsPH, CornerPH, Patch2PH, Image1PH, DirNamesTrain, CornersTrain, NumTrainSamples, ImageSize, NumEpochs, BatchSize, SaveCheckPoint, CheckPointPath, LatestFile, BasePath, LogsPath):\n",
    "\n",
    "    print(\"Unsupervised\")\n",
    "    pred_patch2, true_pathc2,_ = unsupervised_HomographyNet(PatchPairsPH, CornerPH, Patch2PH, Image1PH, BatchSize)\n",
    "\n",
    "    with tf.name_scope('Loss'):\n",
    "        loss = tf.reduce_mean(tf.abs(pred_patch2 - true_pathc2))\n",
    "\n",
    "\n",
    "    with tf.name_scope('Adam'):\n",
    "        Optimizer = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(loss)\n",
    "\n",
    "    # Tensorboard\n",
    "    # Create a summary to monitor loss tensor\n",
    "    EpochLossPH = tf.placeholder(tf.float32, shape=None)\n",
    "    loss_summary = tf.summary.scalar('LossEveryIter', loss)\n",
    "    epoch_loss_summary = tf.summary.scalar('LossPerEpoch', EpochLossPH)\n",
    "    # tf.summary.image('Anything you want', AnyImg)\n",
    "\n",
    "    # Merge all summaries into a single operation\n",
    "    MergedSummaryOP1 = tf.summary.merge([loss_summary])\n",
    "    MergedSummaryOP2 = tf.summary.merge([epoch_loss_summary])\n",
    "    # MergedSummaryOP = tf.summary.merge_all()\n",
    "\n",
    "    # Setup Saver\n",
    "    Saver = tf.train.Saver()\n",
    "    AccOverEpochs=np.array([0,0])\n",
    "\n",
    "    with tf.Session() as sess:  \n",
    "\n",
    "        if LatestFile is not None:\n",
    "            Saver.restore(sess, CheckPointPath + LatestFile + '.ckpt')\n",
    "          # Extract only numbers from the name\n",
    "            StartEpoch = int(''.join(c for c in LatestFile.split('a')[0] if c.isdigit()))\n",
    "            print('Loaded latest checkpoint with the name ' + LatestFile + '....')\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            StartEpoch = 0\n",
    "            print('New model initialized....')\n",
    "\n",
    "        # Tensorboard\n",
    "        Writer = tf.summary.FileWriter(LogsPath, graph=tf.get_default_graph())\n",
    "        \n",
    "        L1_loss = []\n",
    "        for Epochs in tqdm(range(StartEpoch, NumEpochs)):\n",
    "\n",
    "            NumIterationsPerEpoch = int(NumTrainSamples/BatchSize)\n",
    "            Loss=[]\n",
    "            epoch_loss=0\n",
    "\n",
    "            for PerEpochCounter in tqdm(range(NumIterationsPerEpoch)):\n",
    "\n",
    "                PatchPairsBatch, Corner1Batch, patch2Batch, Image1Batch = loadData(BasePath, DirNamesTrain, CornersTrain, BatchSize, shuffle = True)\n",
    "                FeedDict = {PatchPairsPH: PatchPairsBatch, CornerPH: Corner1Batch, Patch2PH: patch2Batch, Image1PH: Image1Batch}\n",
    "\n",
    "                _, LossThisBatch, Summary = sess.run([Optimizer, loss, MergedSummaryOP1], feed_dict=FeedDict)\n",
    "                Loss.append(LossThisBatch)\n",
    "                epoch_loss = epoch_loss + LossThisBatch\n",
    "                \n",
    "                # Save checkpoint every some SaveCheckPoint's iterations\n",
    "#                 if PerEpochCounter % SaveCheckPoint == 0:\n",
    "#                   # Save the Model learnt in this epoch\n",
    "#                     SaveName =  CheckPointPath + str(Epochs) + 'a' + str(PerEpochCounter) + 'model.ckpt'\n",
    "#                     Saver.save(sess,  save_path=SaveName)\n",
    "#                     print('\\n' + SaveName + ' Model Saved...')\n",
    "\n",
    "          # Tensorboard\n",
    "            Writer.add_summary(Summary, Epochs*NumIterationsPerEpoch + PerEpochCounter)\n",
    "            epoch_loss = epoch_loss/NumIterationsPerEpoch\n",
    "\n",
    "            print(\"Printing Epoch:  \",  np.mean(Loss), \"\\n\")\n",
    "            L1_loss.append(np.mean(Loss))\n",
    "          # Save model every epoch\n",
    "            SaveName = CheckPointPath + str(Epochs) + 'model.ckpt'\n",
    "            Saver.save(sess, save_path=SaveName)\n",
    "            print('\\n' + SaveName + ' Model Saved...')\n",
    "            Summary_epoch = sess.run(MergedSummaryOP2,feed_dict={EpochLossPH: epoch_loss})\n",
    "            Writer.add_summary(Summary_epoch,Epochs)\n",
    "            Writer.flush()\n",
    "\n",
    "        np.savetxt(LogsPath + \"LossResults.txt\", np.array(L1_loss), delimiter = \",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BasePath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e1be3cd31a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPatchPairsBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCorner1Batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch2Batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage1Batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles_in_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpointsList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'BasePath' is not defined"
     ]
    }
   ],
   "source": [
    "PatchPairsBatch, Corner1Batch, patch2Batch, Image1Batch = loadData(BasePath, files_in_dir, pointsList, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image1Batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bd044bb36828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage1Batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Image1Batch' is not defined"
     ]
    }
   ],
   "source": [
    "Image1Batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "_RspkcjMRGN0",
    "outputId": "f44dc47b-4e7d-43da-9e4d-ffd19de31ece",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Unsupervised\n",
      "WARNING:tensorflow:From /home/gokul/CMSC733/CMSC733_Project1/Phase2/Code/Network/Network.py:92: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f247c12f940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f247c12f940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f247c12f940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f247c12f940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/gokul/CMSC733/CMSC733_Project1/Phase2/Code/Network/Network.py:93: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/gokul/CMSC733/CMSC733_Project1/Phase2/Code/Network/Network.py:100: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24cb23df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c088d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c088d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24647b3828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24647b3828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24647b3828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f24647b3828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24647b3828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24647b3828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24647b3828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f24647b3828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f246468f278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f246468f278>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f246468f278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f246468f278>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /home/gokul/CMSC733/CMSC733_Project1/Phase2/Code/Network/Network.py:134: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f246c0c2978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f246c0c2978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f246c0c2978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f246c0c2978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /home/gokul/CMSC733/CMSC733_Project1/Phase2/Code/Network/Network.py:135: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f246c0c2978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f246c0c2978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f246c0c2978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f246c0c2978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c0c2978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c0c2978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c0c2978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f246c0c2978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f246c0c2978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f246c0c2978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f246c0c2978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f246c0c2978>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "--Shape of A_mat: [64, 8, 8]\n",
      "--shape of b: [64, 8, 1]\n",
      "WARNING:tensorflow:From /home/gokul/CMSC733/CMSC733_Project1/Phase2/Code/Network/Network.py:76: The name tf.matrix_solve is deprecated. Please use tf.linalg.solve instead.\n",
      "\n",
      "--shape of H_8el Tensor(\"MatrixSolve:0\", shape=(64, 8, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /home/gokul/CMSC733/CMSC733_Project1/Phase2/Code/Misc/TFSpatialTransformer.py:249: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "--Inter- scale_h: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model initialized....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:05<00:30,  5.14s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:06<00:15,  3.04s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:08<00:10,  2.58s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:10<00:06,  2.22s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:11<00:03,  1.69s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:11<00:01,  1.21s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:11<00:00,  1.68s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   43.78756 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:12<03:53, 12.29s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/0model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.63it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  3.52it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:01,  3.20it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:01,  2.53it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:02<00:01,  1.40it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:04<00:01,  1.03s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:05<00:00,  1.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.908512 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:19<02:49,  9.39s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/1model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:03,  1.78it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:02,  2.45it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:01<00:01,  2.80it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:00,  3.05it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:01<00:00,  3.13it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:02<00:00,  3.18it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   44.532986 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:23<01:55,  6.79s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/2model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:08,  1.47s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:03<00:07,  1.57s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:04<00:06,  1.56s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.06s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:01,  1.28it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:05<00:00,  1.63it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:05<00:00,  1.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   46.287727 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:29<01:45,  6.56s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/3model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.59it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  3.38it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:01<00:01,  2.54it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:01,  1.87it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:03<00:01,  1.13it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:04<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:06<00:00,  1.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   44.697765 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:37<01:43,  6.92s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/4model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.29it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  3.30it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:01,  3.40it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:00,  3.45it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:01<00:00,  3.47it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:01<00:00,  3.47it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:02<00:00,  3.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   43.524193 \n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:40<01:20,  5.76s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/5model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:09,  1.56s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:03<00:07,  1.58s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:04<00:05,  1.48s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.01s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:01,  1.33it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:05<00:00,  1.67it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.40293 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:46<01:16,  5.88s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/6model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.31it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:02,  2.30it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:01<00:02,  1.58it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:03<00:02,  1.02it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:04<00:02,  1.20s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:06<00:01,  1.34s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.62804 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:54<01:18,  6.52s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/7model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.41it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  3.50it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:01,  3.44it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:00,  3.46it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:01<00:00,  3.47it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:01<00:00,  2.69it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.544106 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:58<01:04,  5.84s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/8model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:09,  1.62s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:03<00:07,  1.54s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:03,  1.03it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:03<00:02,  1.43it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:03<00:01,  1.82it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:04<00:00,  2.17it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   43.212284 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:04<00:55,  5.59s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/9model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:03,  1.91it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:01<00:02,  1.88it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:02<00:04,  1.01s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.25s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:02,  1.38s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:07<00:01,  1.36s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.561394 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:11<00:56,  6.30s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/10model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.31it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  3.43it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:01,  3.34it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:00,  3.31it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:01<00:00,  2.63it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:02<00:00,  1.67it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.386894 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:17<00:49,  6.20s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/11model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:09,  1.60s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:05,  1.12s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:02<00:02,  1.34it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:02<00:01,  1.78it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:03<00:00,  2.16it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:03<00:00,  1.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   41.55274 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:22<00:40,  5.75s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/12model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:05,  1.11it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:06,  1.27s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:04<00:05,  1.43s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:05<00:04,  1.50s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:06<00:02,  1.32s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:06<00:00,  1.03it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:07<00:00,  1.03s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   41.88322 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:30<00:37,  6.33s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/13model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.57it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  3.52it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:01,  3.38it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:01,  2.61it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:02<00:01,  1.85it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:03<00:00,  1.14it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:05<00:00,  1.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.19207 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:37<00:32,  6.51s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/14model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:06,  1.02s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:01<00:02,  1.69it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:01<00:01,  2.21it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:01,  2.54it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:02<00:00,  2.82it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:02<00:00,  3.02it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   43.044136 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:41<00:23,  5.82s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/15model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:07,  1.22s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:06,  1.23s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:04,  1.24s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:05<00:03,  1.31s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:06<00:02,  1.29s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:07<00:01,  1.27s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:08<00:00,  1.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   44.028927 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:51<00:21,  7.19s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/16model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:07,  1.24s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:06,  1.23s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:04,  1.24s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:05<00:03,  1.32s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:06<00:02,  1.29s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:07<00:01,  1.27s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.07255 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:02<00:16,  8.21s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/17model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:09,  1.58s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:03<00:07,  1.57s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:04<00:06,  1.57s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:06<00:04,  1.57s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:07<00:03,  1.55s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:09<00:01,  1.48s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:10<00:00,  1.48s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   42.33768 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:14<00:09,  9.31s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/18model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [00:01<00:07,  1.24s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:06,  1.23s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:04,  1.25s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:05<00:03,  1.28s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:06<00:02,  1.27s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:07<00:01,  1.25s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:08<00:00,  1.25s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Epoch:   39.50964 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:24<00:00,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/19model.ckpt Model Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BasePath = '/home/gokul/CMSC733/hgokul_p1/Phase2/Data/Train_synthetic/'\n",
    "CheckPointPath = '/home/gokul/CMSC733/hgokul_p1/Phase2/Checkpoints/unsupervised/'\n",
    "\n",
    "files_in_dir, SaveCheckPoint, ImageSize, NumTrainSamples, _ = SetupAll(BasePath, CheckPointPath)\n",
    "LogsPath = '/home/gokul/CMSC733/hgokul_p1/Phase2/Logs/'\n",
    "\n",
    "NumTrainSamples = 500\n",
    "print(NumTrainSamples)\n",
    "\n",
    "pointsList = np.load(BasePath+'/pointsList.npy')\n",
    "\n",
    "batch_size = 64\n",
    "CornerPH = tf.placeholder(tf.float32, shape=(batch_size, 4,2))\n",
    "PatchPairsPH = tf.placeholder(tf.float32, shape=(batch_size, 128, 128 ,2))\n",
    "Patch2PH = tf.placeholder(tf.float32, shape=(batch_size, 128, 128, 1))\n",
    "Images1PH = tf.placeholder(tf.float32, shape=(batch_size, 240, 320, 1))\n",
    "NumEpochs = 20\n",
    "LatestFile = None\n",
    "\n",
    "TrainModel(PatchPairsPH, CornerPH, Patch2PH, Images1PH, files_in_dir, pointsList, NumTrainSamples, ImageSize,\n",
    "           NumEpochs, batch_size, SaveCheckPoint, CheckPointPath, LatestFile, BasePath, LogsPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Train_unsupervised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
