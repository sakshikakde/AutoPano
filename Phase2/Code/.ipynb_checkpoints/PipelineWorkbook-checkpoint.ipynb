{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from skimage import data, exposure, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "from Misc.MiscUtils import *\n",
    "from Misc.DataUtils import *\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import string\n",
    "from termcolor import colored, cprint\n",
    "import math as m\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Don't generate pyc codes\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Activation, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, InputLayer\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCornersFromH4pt(corner1, H4pt):\n",
    "    corners1 = np.array(corner1.copy())\n",
    "    del_corners = H4pt.reshape(2,4).T\n",
    "    corners2 = corners1 + del_corners\n",
    "    return corners2\n",
    "\n",
    "def drawCorners(image, corners, color):\n",
    "\n",
    "    corners_ = np.array(corners.copy())\n",
    "    r = corners_[2,:].copy()\n",
    "    corners_[2,:] = corners_[3,:]\n",
    "    corners_[3,:] = r\n",
    "    corners_ = corners_.reshape(-1,1,2)\n",
    "#     print(corners_)\n",
    "    corners_ = corners_.astype(int)\n",
    "    image_corners = cv2.polylines(image.copy(),[corners_],True,color, 4)\n",
    "    return image_corners\n",
    "\n",
    "def getHfromH4pt(corners1, H4pt):\n",
    "#     print(\"H4pt is: \")\n",
    "#     print(H4pt.reshape(2,4).T)\n",
    "\n",
    "    del_corners = H4pt.reshape(2,4).T\n",
    "    \n",
    "    corners1 = np.array(corners1)\n",
    "#     print(\"corner1 is: \")\n",
    "#     print(corners1)\n",
    "\n",
    "    corners2 = corners1 + del_corners\n",
    "#     print(\"corner2 is: \")\n",
    "#     print(corners2)\n",
    "\n",
    "    H = cv2.getPerspectiveTransform(np.float32(corners1), np.float32(corners2))\n",
    "#     print(\"H is:\")\n",
    "#     print(H)\n",
    "    return H\n",
    "\n",
    "def warpImage(img, corners, H):\n",
    "    image = img.copy()\n",
    "    h, w, _= image.shape\n",
    "\n",
    "    corners_ = np.array(corners)\n",
    "    corners_ = corners_.reshape((-1,1,2))\n",
    "\n",
    "    image_transformed = cv2.warpPerspective(image, H, (w,h))\n",
    "    corner_transformed = cv2.perspectiveTransform(np.float32(corners_), H)\n",
    "    corner_transformed = corner_transformed.astype(int)\n",
    "    \n",
    "    return image_transformed, corner_transformed\n",
    "\n",
    "def HomographyNet():\n",
    "\n",
    "#     hidden_layer_size, num_classes = 1000, 8\n",
    "    input_shape = (128, 128, 2)\n",
    "    kernel_size = 3\n",
    "    pool_size = 2\n",
    "    filters = 64\n",
    "    dropout = 0.5\n",
    "\n",
    "    kernel_initializer = VarianceScaling(scale=2.0)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape))\n",
    "    ## conv2d 128\n",
    "    model.add(Conv2D(filters=filters,kernel_size = kernel_size, activation ='relu', padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    ## conv2d 128\n",
    "    model.add(Conv2D(filters = filters,kernel_size = kernel_size, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size))\n",
    "    \n",
    "    ## conv2d 64\n",
    "    model.add(Conv2D(filters=filters,kernel_size=kernel_size, activation = 'relu', padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    ## conv2d 64\n",
    "    model.add(Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size))\n",
    "    \n",
    "    ## conv2d 32 2x Filters\n",
    "    model.add(Conv2D(filters=filters*2,kernel_size=kernel_size, activation='relu', padding='same',))\n",
    "    model.add(BatchNormalization())\n",
    "    ## conv2d 32 2x Filters\n",
    "    model.add(Conv2D(filters=filters*2,kernel_size=kernel_size, activation='relu', padding='same',))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size))\n",
    "    \n",
    "    ## conv2d 16 2x Filters\n",
    "    model.add(Conv2D(filters=filters*2, kernel_size=kernel_size, activation='relu', padding='same',))\n",
    "    model.add(BatchNormalization())\n",
    "    ## conv2d 16 2x Filters\n",
    "    model.add(Conv2D(filters=filters*2, kernel_size=kernel_size, activation='relu', padding='same',))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    #for regression model\n",
    "    model.add(Dense(8))\n",
    "    return model\n",
    "\n",
    "#Loss Function using SMSE\n",
    "def L2_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files and Load training Data \n",
    "-- all data in memory, not in batches"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_labels = pd.read_csv(\"/home/gokul/CMSC733/hgokul_p1/Phase2/Data/Train_dummy/H4.csv\", index_col =False)\n",
    "all_labels = all_labels.to_numpy()\n",
    "all_patchNames = pd.read_csv(\"/home/gokul/CMSC733/hgokul_p1/Phase2/Data/Train_dummy/ImageFileNames.csv\")\n",
    "all_patchNames = all_patchNames.to_numpy()\n",
    "print(len(all_patchNames),len(all_labels))\n",
    "\n",
    "\n",
    "im1 = cv2.imread(\"/home/gokul/CMSC733/hgokul_p1/Phase2/Data/Train_dummy/PB/\"+ str(all_patchNames[0][0]))\n",
    "plt.imshow(im1)\n",
    "\n",
    "X_train = []\n",
    "for i, p in enumerate(all_patchNames[:1000]):\n",
    "\n",
    "    tPatchA = cv2.imread(\"/home/gokul/CMSC733/hgokul_p1/Phase2/Data/Train_dummy/PA/\"+ str(p[0]), cv2.IMREAD_GRAYSCALE)\n",
    "    tPatchB = cv2.imread(\"/home/gokul/CMSC733/hgokul_p1/Phase2/Data/Train_dummy/PB/\"+ str(p[0]), cv2.IMREAD_GRAYSCALE)\n",
    "    tPatch = np.dstack((tPatchA, tPatchB))    \n",
    "    X_train.append(tPatch)\n",
    "X_train = np.array(X_train)    \n",
    "Y_train = all_labels[:1000]\n",
    "\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model, save and test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "number_of_training_samples = X_train.shape[0]\n",
    "num_iterations_per_epoch = int(number_of_training_samples / batch_size)\n",
    "       \n",
    "model = HomographyNet()\n",
    "adam = optimizers.Adam(lr=0.0005)\n",
    "model.compile(loss= L2_loss, optimizer=adam, metrics=['mean_absolute_error'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=epochs,batch_size = batch_size, verbose=1, shuffle = False)\n",
    "\n",
    "\n",
    "Y_test = model.predict(X_train[1].reshape(1,128,128,2))\n",
    "\n",
    "model.save('model1kOF.h5')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "mae = mean_absolute_error(Y_test, Y_train[1].reshape(1,8))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Unsupervised Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unSuperVised( Img,) :\n",
    "\n",
    "# note : corners_a is in shape 4,2 [[x1,y1][x2,y2][x3,y3][x4,y4]]\n",
    "\n",
    "# H4 = homographyNet(Img, ImageSize, batch_size) # H4 = [dx1,dy1,dx2,dy2,dx3,dy3,dx4,dy4] \n",
    "\n",
    "batch_size = 1\n",
    "corners_a = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "corners_a = tf.constant(corners_a, tf.float32)\n",
    "H4 = tf.constant([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9], tf.float32)\n",
    "\n",
    "\n",
    "corners_a = tf.reshape(corners_a,[batch_size,8]) # convert to 8x1 [x1,y1,x2,y2,x3,y3,x4,y4]\n",
    "\n",
    "# H = TensorDLT(H4 , corners_a, batch_size)\n",
    "H = np.array([[2.0, 0., 2.0],\n",
    "              [0., 2.0, 2.0],\n",
    "              [0., 0., 1.]]).astype(np.float32)\n",
    "H = tf.constant(H, tf.float32) # tensorH\n",
    "\n",
    "\n",
    "# h,w = ImageSize[1],ImageSize[0]\n",
    "h,w = 240,320\n",
    "\n",
    "M = np.array([[w/2.0, 0., w/2.0],\n",
    "              [0., h/2.0, h/2.0],\n",
    "              [0., 0., 1.]]).astype(np.float32)\n",
    "\n",
    "tensor_M = tf.constant(M, tf.float32)\n",
    "tensor_M = tf.expand_dims(tensor_M, [0])\n",
    "M_batches   = tf.tile(tensor_M, [batch_size, 1,1]) # make batch_size number of copies. \n",
    "\n",
    "M_inv = np.linalg.inv(M)\n",
    "tensor_M_inv = tf.constant(M_inv, tf.float32)\n",
    "tensor_M_inv = tf.expand_dims(tensor_M_inv, [0])\n",
    "M_inv_batches   = tf.tile(tensor_M_inv, [batch_size,1,1])\n",
    "\n",
    "# Transform H_mat since we scale image indices in transformer\n",
    "H_scaled = tf.matmul(tf.matmul(M_inv_batches, H), M_batches)\n",
    "\n",
    "# Transform image 1 (large image) to image 2\n",
    "out_size = (h,w)\n",
    "\n",
    "I1 = tf.slice(Img,[0,0,0,0],[MiniBatchSize,128,128,1])\n",
    "print(I1)\n",
    "print(Img)\n",
    "warped_images, _ = transformer(I1, H_mat, out_size)\n",
    "# print(warped_images.get_shape())\n",
    "warped_gray_images = tf.reduce_mean(warped_images, 3)\n",
    "\n",
    "pred_I2_flat = warped_gray_images\n",
    "\n",
    "pred_I2 = tf.reshape(pred_I2_flat, [MiniBatchSize, 128, 128, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "y_t = tf.range(0, batch_size*w*h, w*h)\n",
    "y_t = tf.expand_dims(y_t,[1])\n",
    "z =  tf.tile(y_t,[1,128*128])\n",
    "batch_indices_tensor = tf.reshape(z, [-1]) # Add these value t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "(16384,)\n"
     ]
    }
   ],
   "source": [
    "print(tf.Session().run(batch_indices_tensor))\n",
    "print(tf.Session().run(batch_indices_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c1ae3e04c033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# H4 = homographyNet(Img, ImageSize, batch_size) # H4 = [dx1,dy1,dx2,dy2,dx3,dy3,dx4,dy4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcorners_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcorners_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorners_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mH4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "M_tile   = tf.tile(, [batch_size, 1,1])\n",
    "\n",
    "print(C4A.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model predict H4 and convert to H"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
