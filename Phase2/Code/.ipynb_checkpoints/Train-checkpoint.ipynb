{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from skimage import data, exposure, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "from Misc.MiscUtils import *\n",
    "from Misc.DataUtils import *\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import string\n",
    "from termcolor import colored, cprint\n",
    "import math as m\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Don't generate pyc codes\n",
    "sys.dont_write_bytecode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, InputLayer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(folder_name, files_in_dir, labels_in_dir, num_training=5000):\n",
    "\n",
    "    images_data = []\n",
    "    labels_data = []\n",
    "\n",
    "    if(len(files_in_dir) < num_training):\n",
    "        print(\"The data has only \", len(files_in_dir) , \" images and you are trying to get \",num_training, \" images\")\n",
    "        num_training = len(files_in_dir)\n",
    "\n",
    "    for n in range(num_training):\n",
    "        image1_name = folder_name + os.sep + \"Train_synthetic/PA/\" + files_in_dir[n,0]\n",
    "        image1 = cv2.imread(image1_name)\n",
    "\n",
    "        image2_name = folder_name + os.sep + \"Train_synthetic/PB/\" + files_in_dir[n,0] \n",
    "        image2 = cv2.imread(image2_name)\n",
    "\n",
    "        if(image1 is None) or (image1 is None):\n",
    "            print(image1_name, \" is empty. Ignoring ...\")\n",
    "            continue\n",
    "\n",
    "        image1 = np.float32(image1)\n",
    "        image2 = np.float32(image2)        \n",
    "\n",
    "\n",
    "        #combine images along depth\n",
    "\n",
    "        image = np.dstack((image1, image1))\n",
    "        # #standardize image from \n",
    "        # mean = np.mean(image, axis=(1,2), keepdims=True)\n",
    "        # std = np.std(image, axis=(1,2), keepdims=True)\n",
    "        # standardized_image = (image - mean) / (std + 0.000001)\n",
    "         \n",
    "\n",
    "        labels_data.append(labels_in_dir[n,:])\n",
    "\n",
    "        images_data.append(image)\n",
    "        # labels_data.append(label)\n",
    "\n",
    "    return np.array(images_data), np.array(labels_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDatasetWithBatches(images_data, labels_data, batch_size, shuffle = True):\n",
    "    \n",
    "    N, B = images_data.shape[0], batch_size\n",
    "    idx = np.arange(N)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    return iter((images_data[idx[i:i+B]], labels_data[idx[i:i+B]]) for i in range(0, N, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(ImgPH, LabelPH, dataset, num_epochs, LatestFile, is_training = True):\n",
    "  \n",
    "   #add model optimizer loss etc\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        start_epoch = 0\n",
    "        for epochs in tqdm(range(start_epoch, num_epochs)):\n",
    "            for b, (x, y) in enumerate(dataset):\n",
    "                print(b, x.shape, y.shape)\n",
    "                images_batch = x\n",
    "                labels_batch = y\n",
    "                print(b, images_batch.shape, labels_batch.shape)\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/gokul/CMSC733/hgokul_p1/Phase2/Data/Train_synthetic/ImageFileNames.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2d6b6713fed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mBasePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/gokul/CMSC733/hgokul_p1/Phase2/Data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mCheckPointPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../Checkpoints/supervised/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles_in_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaveCheckPoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumTrainSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSetupAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCheckPointPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CMSC733/CMSC733_Project1/Phase2/Code/Misc/DataUtils.py\u001b[0m in \u001b[0;36mSetupAll\u001b[0;34m(BasePath, CheckPointPath)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \"\"\"\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Setup DirNames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mDirNamesTrain\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mSetupDirNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasePath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/Train_synthetic/ImageFileNames.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Read and Setup Labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMSC733/CMSC733_Project1/Phase2/Code/Misc/DataUtils.py\u001b[0m in \u001b[0;36mSetupDirNames\u001b[0;34m(TxtFilesPath)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mWrites\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTxtFiles\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mDirNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mall\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mDirNamesTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadDirNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTxtFilesPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDirNamesTrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMSC733/CMSC733_Project1/Phase2/Code/Misc/DataUtils.py\u001b[0m in \u001b[0;36mReadDirNames\u001b[0;34m(ReadPath)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# DirNames = DirNames.split()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReadPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/gokul/CMSC733/hgokul_p1/Phase2/Data/Train_synthetic/ImageFileNames.csv'"
     ]
    }
   ],
   "source": [
    "BasePath = \"/home/sakshi/courses/CMSC733/sakshi_p1/Phase2/Data\"\n",
    "BasePath = \"/home/gokul/CMSC733/hgokul_p1/Phase2/Data\"\n",
    "CheckPointPath = \"../Checkpoints/supervised/\"\n",
    "files_in_dir, SaveCheckPoint, ImageSize, NumTrainSamples, labels_in_dir = SetupAll(BasePath, CheckPointPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has only  4985  images and you are trying to get  5000  images\n",
      "(4985, 128, 128, 6)\n",
      "(4985, 128, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "image_dataset, labels = loadData(BasePath, files_in_dir, labels_in_dir, 5000)\n",
    "print(image_dataset.shape)\n",
    "print(image_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = createDatasetWithBatches(image_dataset, labels, batch_size = 50, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]0 (50, 128, 128, 6) (50, 8)\n",
      "0 (50, 128, 128, 6) (50, 8)\n",
      "1 (50, 128, 128, 6) (50, 8)\n",
      "1 (50, 128, 128, 6) (50, 8)\n",
      "2 (50, 128, 128, 6) (50, 8)\n",
      "2 (50, 128, 128, 6) (50, 8)\n",
      "3 (50, 128, 128, 6) (50, 8)\n",
      "3 (50, 128, 128, 6) (50, 8)\n",
      "4 (50, 128, 128, 6) (50, 8)\n",
      "4 (50, 128, 128, 6) (50, 8)\n",
      "5 (50, 128, 128, 6) (50, 8)\n",
      "5 (50, 128, 128, 6) (50, 8)\n",
      "6 (50, 128, 128, 6) (50, 8)\n",
      "6 (50, 128, 128, 6) (50, 8)\n",
      "7 (50, 128, 128, 6) (50, 8)\n",
      "7 (50, 128, 128, 6) (50, 8)\n",
      "8 (50, 128, 128, 6) (50, 8)\n",
      "8 (50, 128, 128, 6) (50, 8)\n",
      "9 (50, 128, 128, 6) (50, 8)\n",
      "9 (50, 128, 128, 6) (50, 8)\n",
      "10 (50, 128, 128, 6) (50, 8)\n",
      "10 (50, 128, 128, 6) (50, 8)\n",
      "11 (50, 128, 128, 6) (50, 8)\n",
      "11 (50, 128, 128, 6) (50, 8)\n",
      "12 (50, 128, 128, 6) (50, 8)\n",
      "12 (50, 128, 128, 6) (50, 8)\n",
      "13 (50, 128, 128, 6) (50, 8)\n",
      "13 (50, 128, 128, 6) (50, 8)\n",
      "14 (50, 128, 128, 6) (50, 8)\n",
      "14 (50, 128, 128, 6) (50, 8)\n",
      "15 (50, 128, 128, 6) (50, 8)\n",
      "15 (50, 128, 128, 6) (50, 8)\n",
      "16 (50, 128, 128, 6) (50, 8)\n",
      "16 (50, 128, 128, 6) (50, 8)\n",
      "17 (50, 128, 128, 6) (50, 8)\n",
      "17 (50, 128, 128, 6) (50, 8)\n",
      "18 (50, 128, 128, 6) (50, 8)\n",
      "18 (50, 128, 128, 6) (50, 8)\n",
      "19 (50, 128, 128, 6) (50, 8)\n",
      "19 (50, 128, 128, 6) (50, 8)\n",
      "20 (50, 128, 128, 6) (50, 8)\n",
      "20 (50, 128, 128, 6) (50, 8)\n",
      "21 (50, 128, 128, 6) (50, 8)\n",
      "21 (50, 128, 128, 6) (50, 8)\n",
      "22 (50, 128, 128, 6) (50, 8)\n",
      "22 (50, 128, 128, 6) (50, 8)\n",
      "23 (50, 128, 128, 6) (50, 8)\n",
      "23 (50, 128, 128, 6) (50, 8)\n",
      "24 (50, 128, 128, 6) (50, 8)\n",
      "24 (50, 128, 128, 6) (50, 8)\n",
      "25 (50, 128, 128, 6) (50, 8)\n",
      "25 (50, 128, 128, 6) (50, 8)\n",
      "26 (50, 128, 128, 6) (50, 8)\n",
      "26 (50, 128, 128, 6) (50, 8)\n",
      "27 (50, 128, 128, 6) (50, 8)\n",
      "27 (50, 128, 128, 6) (50, 8)\n",
      "28 (50, 128, 128, 6) (50, 8)\n",
      "28 (50, 128, 128, 6) (50, 8)\n",
      "29 (50, 128, 128, 6) (50, 8)\n",
      "29 (50, 128, 128, 6) (50, 8)\n",
      "30 (50, 128, 128, 6) (50, 8)\n",
      "30 (50, 128, 128, 6) (50, 8)\n",
      "31 (50, 128, 128, 6) (50, 8)\n",
      "31 (50, 128, 128, 6) (50, 8)\n",
      "32 (50, 128, 128, 6) (50, 8)\n",
      "32 (50, 128, 128, 6) (50, 8)\n",
      "33 (50, 128, 128, 6) (50, 8)\n",
      "33 (50, 128, 128, 6) (50, 8)\n",
      "34 (50, 128, 128, 6) (50, 8)\n",
      "34 (50, 128, 128, 6) (50, 8)\n",
      "35 (50, 128, 128, 6) (50, 8)\n",
      "35 (50, 128, 128, 6) (50, 8)\n",
      "36 (50, 128, 128, 6) (50, 8)\n",
      "36 (50, 128, 128, 6) (50, 8)\n",
      "37 (50, 128, 128, 6) (50, 8)\n",
      "37 (50, 128, 128, 6) (50, 8)\n",
      "38 (50, 128, 128, 6) (50, 8)\n",
      "38 (50, 128, 128, 6) (50, 8)\n",
      "39 (50, 128, 128, 6) (50, 8)\n",
      "39 (50, 128, 128, 6) (50, 8)\n",
      "40 (50, 128, 128, 6) (50, 8)\n",
      "40 (50, 128, 128, 6) (50, 8)\n",
      "41 (50, 128, 128, 6) (50, 8)\n",
      "41 (50, 128, 128, 6) (50, 8)\n",
      "42 (50, 128, 128, 6) (50, 8)\n",
      "42 (50, 128, 128, 6) (50, 8)\n",
      "43 (50, 128, 128, 6) (50, 8)\n",
      "43 (50, 128, 128, 6) (50, 8)\n",
      "44 (50, 128, 128, 6) (50, 8)\n",
      "44 (50, 128, 128, 6) (50, 8)\n",
      "45 (50, 128, 128, 6) (50, 8)\n",
      "45 (50, 128, 128, 6) (50, 8)\n",
      "46 (50, 128, 128, 6) (50, 8)\n",
      "46 (50, 128, 128, 6) (50, 8)\n",
      "47 (50, 128, 128, 6) (50, 8)\n",
      "47 (50, 128, 128, 6) (50, 8)\n",
      "48 (50, 128, 128, 6) (50, 8)\n",
      "48 (50, 128, 128, 6) (50, 8)\n",
      "49 (50, 128, 128, 6) (50, 8)\n",
      "49 (50, 128, 128, 6) (50, 8)\n",
      "50 (50, 128, 128, 6) (50, 8)\n",
      "50 (50, 128, 128, 6) (50, 8)\n",
      "51 (50, 128, 128, 6) (50, 8)\n",
      "51 (50, 128, 128, 6) (50, 8)\n",
      "52 (50, 128, 128, 6) (50, 8)\n",
      "52 (50, 128, 128, 6) (50, 8)\n",
      "53 (50, 128, 128, 6) (50, 8)\n",
      "53 (50, 128, 128, 6) (50, 8)\n",
      "54 (50, 128, 128, 6) (50, 8)\n",
      "54 (50, 128, 128, 6) (50, 8)\n",
      "55 (50, 128, 128, 6) (50, 8)\n",
      "55 (50, 128, 128, 6) (50, 8)\n",
      "56 (50, 128, 128, 6) (50, 8)\n",
      "56 (50, 128, 128, 6) (50, 8)\n",
      "57 (50, 128, 128, 6) (50, 8)\n",
      "57 (50, 128, 128, 6) (50, 8)\n",
      "58 (50, 128, 128, 6) (50, 8)\n",
      "58 (50, 128, 128, 6) (50, 8)\n",
      "59 (50, 128, 128, 6) (50, 8)\n",
      "59 (50, 128, 128, 6) (50, 8)\n",
      "60 (50, 128, 128, 6) (50, 8)\n",
      "60 (50, 128, 128, 6) (50, 8)\n",
      "61 (50, 128, 128, 6) (50, 8)\n",
      "61 (50, 128, 128, 6) (50, 8)\n",
      "62 (50, 128, 128, 6) (50, 8)\n",
      "62 (50, 128, 128, 6) (50, 8)\n",
      "63 (50, 128, 128, 6) (50, 8)\n",
      "63 (50, 128, 128, 6) (50, 8)\n",
      "64 (50, 128, 128, 6) (50, 8)\n",
      "64 (50, 128, 128, 6) (50, 8)\n",
      "65 (50, 128, 128, 6) (50, 8)\n",
      "65 (50, 128, 128, 6) (50, 8)\n",
      "66 (50, 128, 128, 6) (50, 8)\n",
      "66 (50, 128, 128, 6) (50, 8)\n",
      "67 (50, 128, 128, 6) (50, 8)\n",
      "67 (50, 128, 128, 6) (50, 8)\n",
      "68 (50, 128, 128, 6) (50, 8)\n",
      "68 (50, 128, 128, 6) (50, 8)\n",
      "69 (50, 128, 128, 6) (50, 8)\n",
      "69 (50, 128, 128, 6) (50, 8)\n",
      "70 (50, 128, 128, 6) (50, 8)\n",
      "70 (50, 128, 128, 6) (50, 8)\n",
      "71 (50, 128, 128, 6) (50, 8)\n",
      "71 (50, 128, 128, 6) (50, 8)\n",
      "72 (50, 128, 128, 6) (50, 8)\n",
      "72 (50, 128, 128, 6) (50, 8)\n",
      "73 (50, 128, 128, 6) (50, 8)\n",
      "73 (50, 128, 128, 6) (50, 8)\n",
      "74 (50, 128, 128, 6) (50, 8)\n",
      "74 (50, 128, 128, 6) (50, 8)\n",
      "75 (50, 128, 128, 6) (50, 8)\n",
      "75 (50, 128, 128, 6) (50, 8)\n",
      "76 (50, 128, 128, 6) (50, 8)\n",
      "76 (50, 128, 128, 6) (50, 8)\n",
      "77 (50, 128, 128, 6) (50, 8)\n",
      "77 (50, 128, 128, 6) (50, 8)\n",
      "78 (50, 128, 128, 6) (50, 8)\n",
      "78 (50, 128, 128, 6) (50, 8)\n",
      "79 (50, 128, 128, 6) (50, 8)\n",
      "79 (50, 128, 128, 6) (50, 8)\n",
      "80 (50, 128, 128, 6) (50, 8)\n",
      "80 (50, 128, 128, 6) (50, 8)\n",
      "81 (50, 128, 128, 6) (50, 8)\n",
      "81 (50, 128, 128, 6) (50, 8)\n",
      "82 (50, 128, 128, 6) (50, 8)\n",
      "82 (50, 128, 128, 6) (50, 8)\n",
      "83 (50, 128, 128, 6) (50, 8)\n",
      "83 (50, 128, 128, 6) (50, 8)\n",
      "84 (50, 128, 128, 6) (50, 8)\n",
      "84 (50, 128, 128, 6) (50, 8)\n",
      "85 (50, 128, 128, 6) (50, 8)\n",
      "85 (50, 128, 128, 6) (50, 8)\n",
      "86 (50, 128, 128, 6) (50, 8)\n",
      "86 (50, 128, 128, 6) (50, 8)\n",
      "87 (50, 128, 128, 6) (50, 8)\n",
      "87 (50, 128, 128, 6) (50, 8)\n",
      "88 (50, 128, 128, 6) (50, 8)\n",
      "88 (50, 128, 128, 6) (50, 8)\n",
      "89 (50, 128, 128, 6) (50, 8)\n",
      "89 (50, 128, 128, 6) (50, 8)\n",
      "90 (50, 128, 128, 6) (50, 8)\n",
      "90 (50, 128, 128, 6) (50, 8)\n",
      "91 (50, 128, 128, 6) (50, 8)\n",
      "91 (50, 128, 128, 6) (50, 8)\n",
      "92 (50, 128, 128, 6) (50, 8)\n",
      "92 (50, 128, 128, 6) (50, 8)\n",
      "93 (50, 128, 128, 6) (50, 8)\n",
      "93 (50, 128, 128, 6) (50, 8)\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]94 (50, 128, 128, 6) (50, 8)\n",
      "94 (50, 128, 128, 6) (50, 8)\n",
      "95 (50, 128, 128, 6) (50, 8)\n",
      "95 (50, 128, 128, 6) (50, 8)\n",
      "96 (50, 128, 128, 6) (50, 8)\n",
      "96 (50, 128, 128, 6) (50, 8)\n",
      "97 (50, 128, 128, 6) (50, 8)\n",
      "97 (50, 128, 128, 6) (50, 8)\n",
      "98 (50, 128, 128, 6) (50, 8)\n",
      "98 (50, 128, 128, 6) (50, 8)\n",
      "99 (35, 128, 128, 6) (35, 8)\n",
      "99 (35, 128, 128, 6) (35, 8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ImgPH = None\n",
    "LabelPH = None\n",
    "LatestFile = None\n",
    "trainModel(ImgPH, LabelPH, dataset, 1, LatestFile, is_training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
