{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indian-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gokul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 830159302885005805\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12572987049514984280\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from skimage import data, exposure, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "from Misc.MiscUtils import *\n",
    "from Misc.DataUtils import *\n",
    "from Network.Network import *\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import shutil\n",
    "from io import StringIO\n",
    "import string\n",
    "from termcolor import colored, cprint\n",
    "import math as m\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Don't generate pyc codes\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Activation, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, InputLayer\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-annotation",
   "metadata": {},
   "source": [
    "# Load Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "golden-singles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3386: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2888: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:158: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/gokul/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:625: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Shape of X_test and Y_test  (5000, 128, 128, 2) (5000, 8)\n",
      "Mean Absolute Error:  5.5945354533604785\n",
      "Mean Squared Error:  55.69754026930949\n"
     ]
    }
   ],
   "source": [
    "# loads all data in csv\n",
    "BasePath = \"/home/gokul/CMSC733/Project1_dummy/Phase2/Data/Test_synthetic\"\n",
    "ModelPath = \"/home/gokul/CMSC733/hgokul_p1/Phase2/Results/25kmodel/model25k.h5\"\n",
    "SavePath = \"/home/gokul/CMSC733/Project1_dummy/Phase2/Code/Results/\"\n",
    "\n",
    "def Test_supervised(BasePath, ModelPath, SavePath):\n",
    "    \n",
    "    SavePath = SavePath+'supervised/'\n",
    "    if(not (os.path.isdir(SavePath))):\n",
    "        print(SavePath, \"  was not present, creating the folder...\")\n",
    "        os.makedirs(SavePath)\n",
    "\n",
    "    model = load_model(ModelPath, custom_objects={'L2_loss': L2_loss})\n",
    "\n",
    "    all_labels = pd.read_csv(BasePath+\"/H4.csv\", index_col =False)\n",
    "    all_labels = all_labels.to_numpy()\n",
    "    all_patchNames = pd.read_csv(BasePath+\"/ImageFileNames.csv\")\n",
    "    all_patchNames = all_patchNames.to_numpy()\n",
    "\n",
    "    X_test = []\n",
    "    for p in all_patchNames:\n",
    "    #     print(p)\n",
    "        tPatchA = cv2.imread(BasePath+\"/PA/\"+ str(p[0]), cv2.IMREAD_GRAYSCALE)\n",
    "        tPatchB = cv2.imread(BasePath+\"/PB/\"+ str(p[0]), cv2.IMREAD_GRAYSCALE)\n",
    "        tPatch = np.dstack((tPatchA, tPatchB))    \n",
    "        X_test.append(tPatch)\n",
    "\n",
    "    X_test = np.array(X_test)    \n",
    "    Y_true = all_labels\n",
    "\n",
    "    print(\"Shape of X_test and Y_test \", X_test.shape,Y_true.shape)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    np.save(SavePath+\"Y_Pred.npy\",Y_pred)\n",
    "    \n",
    "    mae = mean_absolute_error(Y_true, Y_pred)\n",
    "    mse = mean_squared_error(Y_true, Y_pred)\n",
    "     \n",
    "    print(\"Mean Absolute Error: \", mae)\n",
    "    print(\"Mean Squared Error: \", mse)\n",
    "    \n",
    "    return None\n",
    "\n",
    "Test_supervised(BasePath, ModelPath, SavePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-practice",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fancy-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions \n",
    "\n",
    "def getCornersFromH4pt(corner1, H4pt):\n",
    "    corners1 = np.array(corner1.copy())\n",
    "    del_corners = H4pt.reshape(2,4).T\n",
    "    corners2 = corners1 + del_corners\n",
    "    return corners2\n",
    "\n",
    "def drawCorners(image, corners, color):\n",
    "\n",
    "    corners_ = np.array(corners.copy())\n",
    "    r = corners_[2,:].copy()\n",
    "    corners_[2,:] = corners_[3,:]\n",
    "    corners_[3,:] = r\n",
    "    corners_ = corners_.reshape(-1,1,2)\n",
    "#     print(corners_)\n",
    "    corners_ = corners_.astype(int)\n",
    "    image_corners = cv2.polylines(image.copy(),[corners_],True,color, 4)\n",
    "    return image_corners\n",
    "\n",
    "def getHfromH4pt(corners1, H4pt):\n",
    "#     print(\"H4pt is: \")\n",
    "#     print(H4pt.reshape(2,4).T)\n",
    "\n",
    "    del_corners = H4pt.reshape(2,4).T\n",
    "    \n",
    "    corners1 = np.array(corners1)\n",
    "#     print(\"corner1 is: \")\n",
    "#     print(corners1)\n",
    "\n",
    "    corners2 = corners1 + del_corners\n",
    "#     print(\"corner2 is: \")\n",
    "#     print(corners2)\n",
    "\n",
    "    H = cv2.getPerspectiveTransform(np.float32(corners1), np.float32(corners2))\n",
    "#     print(\"H is:\")\n",
    "#     print(H)\n",
    "    return H\n",
    "\n",
    "def warpImage(img, corners, H):\n",
    "    image = img.copy()\n",
    "    h, w, _= image.shape\n",
    "\n",
    "    corners_ = np.array(corners)\n",
    "    corners_ = corners_.reshape((-1,1,2))\n",
    "\n",
    "    image_transformed = cv2.warpPerspective(image, H, (w,h))\n",
    "    corner_transformed = cv2.perspectiveTransform(np.float32(corners_), H)\n",
    "    corner_transformed = corner_transformed.astype(int)\n",
    "    \n",
    "    return image_transformed, corner_transformed\n",
    "\n",
    "def Visualise_supervised(i, BasePath, SavePath):\n",
    "    \n",
    "    pointsList = np.load(BasePath+'/pointsList.npy')\n",
    "    Y_Pred = np.load(SavePath+'supervised/Y_Pred.npy')\n",
    "    \n",
    "    Y_true  = pd.read_csv(BasePath+\"/H4.csv\", index_col =False)\n",
    "    Y_true = Y_true.to_numpy()\n",
    "    all_patchNames = pd.read_csv(BasePath+\"/ImageFileNames.csv\")\n",
    "    all_patchNames = all_patchNames.to_numpy()\n",
    "    print(len(all_patchNames),len(Y_true))\n",
    "\n",
    "\n",
    "    corners_a = pointsList[i,:,:,0]\n",
    "    corners_b = pointsList[i,:,:,1]\n",
    "\n",
    "    imPathA = BasePath + '/IA/' + all_patchNames[i,0]\n",
    "    imA = cv2.imread(imPathA)\n",
    "\n",
    "    H_AB = getHfromH4pt(corners_a, Y_true[i])\n",
    "    imB, corners_b_cal = warpImage(imA, corners_a, H_AB)\n",
    "\n",
    "    imA_corners = drawCorners(imA, corners_a, (0,0,255))\n",
    "    imB_corners = drawCorners(imB, corners_b_cal, (0,0,255))\n",
    "\n",
    "    mae = mean_absolute_error(Y_Pred[i], Y_true[i])\n",
    "    print(\"Mean absolute Error for image at index \",i, \":  \",mae)\n",
    "\n",
    "    corners_b_pred = getCornersFromH4pt(corners_a, Y_Pred[i])\n",
    "    # imA_corners = drawCorners(imA, pts1, (0,0,255))\n",
    "    imB_corners_pred = drawCorners(imB_corners, corners_b_pred, (0,255,0))\n",
    "    \n",
    "    return np.hstack((imA_corners,imB_corners_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "turned-failure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n",
      "(5000, 128, 128, 2) (5000, 8)\n",
      "Mean absolute Error for image at index  243 :   4.235666040331125\n",
      "5000 5000\n",
      "(5000, 128, 128, 2) (5000, 8)\n",
      "Mean absolute Error for image at index  872 :   5.362352758646011\n",
      "5000 5000\n",
      "(5000, 128, 128, 2) (5000, 8)\n",
      "Mean absolute Error for image at index  1522 :   8.236723020672798\n",
      "5000 5000\n",
      "(5000, 128, 128, 2) (5000, 8)\n",
      "Mean absolute Error for image at index  280 :   6.385164350271225\n",
      "5000 5000\n",
      "(5000, 128, 128, 2) (5000, 8)\n",
      "Mean absolute Error for image at index  637 :   8.64943927526474\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rand_i = np.random.randint(0,4999, size=5)\n",
    "for i in rand_i:\n",
    "    comparison = Visualise_supervised(i, BasePath, SavePath)\n",
    "    cv2.imwrite(SavePath+'supervised/comparison'+ str(i)+'.png',comparison)\n",
    "\n",
    "# plt.imshow(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
